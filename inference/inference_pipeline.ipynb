{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Data Mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mount: exec /Library/Filesystems/nfs4.fs/Contents/Resources/mount_nfs4 for /Users/purgatorid/Documents/GitHub/Project Canopy/cb_feature_detection/inference/efs_inference_data: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport 172.31.91.151:/ ./efs_inference_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Docker Run / Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio geopandas shapely tensorflow-addons[tensorflow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Local / Sagemaker Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from rasterio.windows import Window\n",
    "from glob import glob\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "from rasterio.windows import get_data_window\n",
    "import rasterio as rio\n",
    "from inference_predict import *\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import gdal\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.vrt import WarpedVRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(img_dim, patch_size=(240, 240), stride=(240, 240)):\n",
    "    patch_size = np.array(patch_size)\n",
    "    stride = np.array(stride)\n",
    "    img_dim = np.array(img_dim)\n",
    "    # to take into account edges, add additional blocks around right side edge and bottom edge of raster\n",
    "    new_img_dim = [img_dim[0] + stride[0],img_dim[1] + stride[0]]\n",
    "    \n",
    "    max_dim = (new_img_dim//patch_size)*patch_size - patch_size\n",
    "\n",
    "    ys = np.arange(0, img_dim[0], stride[0])\n",
    "    xs = np.arange(0, img_dim[1], stride[1])\n",
    "\n",
    "    tlc = np.array(np.meshgrid(ys, xs)).T.reshape(-1, 2)\n",
    "    tlc = tlc[tlc[:, 0] <= max_dim[0]]\n",
    "    tlc = tlc[tlc[:, 1] <= max_dim[1]]\n",
    "    \n",
    "    windows = []\n",
    "    for y,x in tlc.astype(int):\n",
    "        windows.append(Window(x, y, patch_size[1], patch_size[0]))\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ndvi(data, dtype_1=rio.float32):\n",
    "    \n",
    "    nir = data[3].astype(dtype_1)\n",
    "    red = data[2].astype(dtype_1)\n",
    "\n",
    "    # Allow division by zero\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi = ((nir - red) / (nir + red)).astype(dtype_1)\n",
    "\n",
    "    # Rescaling for use in 16bit output\n",
    "\n",
    "    ndvi = (ndvi + 1) * (2**15 - 1)\n",
    "\n",
    "    # Add NDVI band to end of array    \n",
    "    rast = np.concatenate((data,[ndvi]),axis=0)\n",
    "    \n",
    "    rast = rast.astype(rio.uint16)\n",
    "    \n",
    "    return rast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_url = \"s3://canopy-production-ml/inference/model_files/model-best.h5\"\n",
    "# weights_url = \"s3://canopy-production-ml/inference/model_files/model_weights_best.h5\"\n",
    "\n",
    "# download_model(model_url,weights_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model.h5\",\"model_weights.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"Industrial_agriculture\",\"ISL\",\"Mining\",\"Roads\",\"Shifting_cultivation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_windows(granule_dir,patch_size=100,\n",
    "                   stride=100,SAVE=False,SAVE_INDIVIDUAL=False,\n",
    "                   bands=[2, 3, 4, 8, 11, 12], \n",
    "                  model=model,\n",
    "                   predict_thresh=.5,\n",
    "                  label_list=label_list, \n",
    "                  job_name=\"test_inference\", \n",
    "                  output_filename=\"./inference_output/result.json\"):\n",
    "    \n",
    "    granule_list = glob(f'{granule_dir}/*.tif')\n",
    "    \n",
    "    output_dict = {}\n",
    "    \n",
    "    granule_id_list = []\n",
    "    \n",
    "    window_id_list = []\n",
    "    \n",
    "    window_geom_list = []\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    label_master_list = []\n",
    "    \n",
    "    gdf_list = []\n",
    "    \n",
    "    timestamp = gen_timestamp()\n",
    "    \n",
    "    for j,granule_path in enumerate(granule_list[0:1]):\n",
    "        \n",
    "        granule_id = granule_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "    \n",
    "        with rio.open(granule_path) as src:\n",
    "            \n",
    "            with WarpedVRT(src, crs='EPSG:3257', resampling=Resampling.nearest) as vrt:\n",
    "\n",
    "                windows = get_windows(vrt.shape, (patch_size, patch_size), (stride, stride))\n",
    "\n",
    "                for i, window in enumerate(windows[0:10]):\n",
    "\n",
    "                    print(f\"predicting window {i + 1} of {len(windows)} of granulate {j + 1} of {len(granule_list)}\",end='\\r', flush=True)\n",
    "\n",
    "                    label_name_list = []\n",
    "\n",
    "                    window_id = i+1\n",
    "\n",
    "                    data = vrt.read(bands,window=window, masked=True)\n",
    "\n",
    "                    data = add_ndvi(data)\n",
    "\n",
    "                    shape = data.shape\n",
    "\n",
    "                    new_shape = (data.shape[0],patch_size,patch_size)\n",
    "\n",
    "                    if shape != new_shape:\n",
    "\n",
    "                        filled_array = np.full(new_shape, 0)\n",
    "                        filled_array[:shape[0],:shape[1],:shape[2]] = data\n",
    "                        data = filled_array\n",
    "                        window = Window(window.col_off,window.row_off,shape[2],shape[1])\n",
    "\n",
    "\n",
    "                    #image pre-processing / inference\n",
    "                    prediction = model.predict(read_image_tf_out(data))\n",
    "                    prediction = np.where(prediction > predict_thresh, 1, 0)\n",
    "                    prediction_i = np.where(prediction == 1)[1]\n",
    "                    for i in prediction_i:\n",
    "                        label_name_list.append(label_list[i])\n",
    "\n",
    "                    label_master_list.append(label_name_list)\n",
    "\n",
    "                    #vectorizing raster bounds for visualization \n",
    "                    window_bounds = rio.windows.bounds(window, vrt.transform, height=patch_size, width=patch_size)\n",
    "                    geom = box(*window_bounds)\n",
    "                    geom_coords = list(geom.exterior.coords)\n",
    "    #                 window_geom_list.append(geom)\n",
    "\n",
    "                    #create or append to dict....\n",
    "\n",
    "                    if granule_id in output_dict:\n",
    "\n",
    "                        output_dict[granule_id].append({\"window_id\":window_id,\"polygon_coords\":geom_coords,\"labels\":label_name_list})\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        output_dict[granule_id] = [{\"window_id\":window_id,\"polygon_coords\":geom_coords,\"labels\":label_name_list}]\n",
    "\n",
    "            save_to_s3(output_dict,output_filename,job_name,timestamp)\n",
    "\n",
    "\n",
    "\n",
    "    #             gdf = gpd.GeoDataFrame({\"granule_id\":granule_id_list,\"window_id\":window_id_list,\"geometry\":window_geom_list,\"labels\":label_master_list})\n",
    "    #             gdf[\"labels\"] = gdf[\"labels\"].astype(str)\n",
    "\n",
    "    #             gdf_list.append(gdf)\n",
    "            \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "CRSError",
     "evalue": "The EPSG code is unknown. PROJ: proj_create_from_database: /Users/purgatorid/opt/anaconda3/envs/infer-conda/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mrasterio/_crs.pyx\u001b[0m in \u001b[0;36mrasterio._crs._CRS.from_epsg\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_err.pyx\u001b[0m in \u001b[0;36mrasterio._err.exc_wrap_int\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m: PROJ: proj_create_from_database: /Users/purgatorid/opt/anaconda3/envs/infer-conda/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCRSError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7716702584a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgranule_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/purgatorid/Downloads/granule_test/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgranule_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-d137cc5e136c>\u001b[0m in \u001b[0;36moutput_windows\u001b[0;34m(granule_dir, patch_size, stride, SAVE, SAVE_INDIVIDUAL, bands, model, predict_thresh, label_list, job_name, output_filename)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgranule_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mWarpedVRT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EPSG:3257'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mResampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnearest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvrt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mwindows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mrasterio/_warp.pyx\u001b[0m in \u001b[0;36mrasterio._warp.WarpedVRTReaderBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infer-conda/lib/python3.7/site-packages/rasterio/crs.py\u001b[0m in \u001b[0;36mfrom_user_input\u001b[0;34m(cls, value, morph_from_esri_dialect)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmorph_from_esri_dialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmorph_from_esri_dialect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCRSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CRS is invalid: {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infer-conda/lib/python3.7/site-packages/rasterio/crs.py\u001b[0m in \u001b[0;36mfrom_string\u001b[0;34m(cls, string, morph_from_esri_dialect)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCRSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid CRS: {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_epsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/infer-conda/lib/python3.7/site-packages/rasterio/crs.py\u001b[0m in \u001b[0;36mfrom_epsg\u001b[0;34m(cls, code)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \"\"\"\n\u001b[1;32m    332\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_epsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mrasterio/_crs.pyx\u001b[0m in \u001b[0;36mrasterio._crs._CRS.from_epsg\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCRSError\u001b[0m: The EPSG code is unknown. PROJ: proj_create_from_database: /Users/purgatorid/opt/anaconda3/envs/infer-conda/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation."
     ]
    }
   ],
   "source": [
    "# granule_dir = \"./efs_inference_data/\"\n",
    "granule_dir = \"/Users/purgatorid/Downloads/granule_test/\"\n",
    "\n",
    "output_dict = output_windows(granule_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class WarpedVRT in module rasterio.vrt:\n",
      "\n",
      "class WarpedVRT(rasterio._warp.WarpedVRTReaderBase, rasterio.windows.WindowMethodsMixin, rasterio.transform.TransformMethodsMixin)\n",
      " |  A virtual warped dataset.\n",
      " |  \n",
      " |  Abstracts the details of raster warping and allows access to data\n",
      " |  that is reprojected when read.\n",
      " |  \n",
      " |  This class is backed by an in-memory GDAL VRTWarpedDataset VRT file.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  src_dataset : dataset object\n",
      " |      The warp source.\n",
      " |  src_crs : CRS or str, optional\n",
      " |      Overrides the coordinate reference system of `src_dataset`.\n",
      " |  src_transfrom : Affine, optional\n",
      " |      Overrides the transform of `src_dataset`.\n",
      " |  src_nodata : float, optional\n",
      " |      Overrides the nodata value of `src_dataset`, which is the\n",
      " |      default.\n",
      " |  crs : CRS or str, optional\n",
      " |      The coordinate reference system at the end of the warp\n",
      " |      operation.  Default: the crs of `src_dataset`. dst_crs is\n",
      " |      a deprecated alias for this parameter.\n",
      " |  transform : Affine, optional\n",
      " |      The transform for the virtual dataset. Default: will be\n",
      " |      computed from the attributes of `src_dataset`. dst_transform\n",
      " |      is a deprecated alias for this parameter.\n",
      " |  height, width: int, optional\n",
      " |      The dimensions of the virtual dataset. Defaults: will be\n",
      " |      computed from the attributes of `src_dataset`. dst_height\n",
      " |      and dst_width are deprecated alias for these parameters.\n",
      " |  nodata : float, optional\n",
      " |      Nodata value for the virtual dataset. Default: the nodata\n",
      " |      value of `src_dataset` or 0.0. dst_nodata is a deprecated\n",
      " |      alias for this parameter.\n",
      " |  resampling : Resampling, optional\n",
      " |      Warp resampling algorithm. Default: `Resampling.nearest`.\n",
      " |  tolerance : float, optional\n",
      " |      The maximum error tolerance in input pixels when\n",
      " |      approximating the warp transformation. Default: 0.125,\n",
      " |      or one-eigth of a pixel.\n",
      " |  src_alpha : int, optional\n",
      " |      Index of a source band to use as an alpha band for warping.\n",
      " |  add_alpha : bool, optional\n",
      " |      Whether to add an alpha masking band to the virtual dataset.\n",
      " |      Default: False. This option will cause deletion of the VRT\n",
      " |      nodata value.\n",
      " |  init_dest_nodata : bool, optional\n",
      " |      Whether or not to initialize output to `nodata`. Default:\n",
      " |      True.\n",
      " |  warp_mem_limit : int, optional\n",
      " |      The warp operation's memory limit in MB. The default (0)\n",
      " |      means 64 MB with GDAL 2.2.\n",
      " |  dtype : str, optional\n",
      " |      The working data type for warp operation and output.\n",
      " |  warp_extras : dict\n",
      " |      GDAL extra warp options. See\n",
      " |      https://gdal.org/doxygen/structGDALWarpOptions.html.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  src_dataset : dataset\n",
      " |      The dataset object to be virtually warped.\n",
      " |  resampling : int\n",
      " |      One of the values from rasterio.enums.Resampling. The default is\n",
      " |      `Resampling.nearest`.\n",
      " |  tolerance : float\n",
      " |      The maximum error tolerance in input pixels when approximating\n",
      " |      the warp transformation. The default is 0.125.\n",
      " |  src_nodata: int or float, optional\n",
      " |      The source nodata value.  Pixels with this value will not be\n",
      " |      used for interpolation. If not set, it will be default to the\n",
      " |      nodata value of the source image, if available.\n",
      " |  dst_nodata: int or float, optional\n",
      " |      The nodata value used to initialize the destination; it will\n",
      " |      remain in all areas not covered by the reprojected source.\n",
      " |      Defaults to the value of src_nodata, or 0 (gdal default).\n",
      " |  working_dtype : str, optional\n",
      " |      The working data type for warp operation and output.\n",
      " |  warp_extras : dict\n",
      " |      GDAL extra warp options. See\n",
      " |      https://gdal.org/doxygen/structGDALWarpOptions.html.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> with rasterio.open('tests/data/RGB.byte.tif') as src:\n",
      " |  ...     with WarpedVRT(src, crs='EPSG:3857') as vrt:\n",
      " |  ...         data = vrt.read()\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      WarpedVRT\n",
      " |      rasterio._warp.WarpedVRTReaderBase\n",
      " |      rasterio._io.DatasetReaderBase\n",
      " |      rasterio._base.DatasetBase\n",
      " |      rasterio.windows.WindowMethodsMixin\n",
      " |      rasterio.transform.TransformMethodsMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, *args, **kwargs)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from rasterio._warp.WarpedVRTReaderBase:\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      Make a virtual warped dataset\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      src_dataset : dataset object\n",
      " |          The warp source dataset. Must be opened in \"r\" mode.\n",
      " |      src_crs : CRS or str, optional\n",
      " |          Overrides the coordinate reference system of `src_dataset`.\n",
      " |      src_transfrom : Affine, optional\n",
      " |          Overrides the transform of `src_dataset`.\n",
      " |      src_nodata : float, optional\n",
      " |          Overrides the nodata value of `src_dataset`, which is the\n",
      " |          default.\n",
      " |      crs : CRS or str, optional\n",
      " |          The coordinate reference system at the end of the warp\n",
      " |          operation.  Default: the crs of `src_dataset`. dst_crs is\n",
      " |          a deprecated alias for this parameter.\n",
      " |      transform : Affine, optional\n",
      " |          The transform for the virtual dataset. Default: will be\n",
      " |          computed from the attributes of `src_dataset`. dst_transform\n",
      " |          is a deprecated alias for this parameter.\n",
      " |      height, width: int, optional\n",
      " |          The dimensions of the virtual dataset. Defaults: will be\n",
      " |          computed from the attributes of `src_dataset`. dst_height\n",
      " |          and dst_width are deprecated alias for these parameters.\n",
      " |      nodata : float, optional\n",
      " |          Nodata value for the virtual dataset. Default: the nodata\n",
      " |          value of `src_dataset` or 0.0. dst_nodata is a deprecated\n",
      " |          alias for this parameter.\n",
      " |      resampling : Resampling, optional\n",
      " |          Warp resampling algorithm. Default: `Resampling.nearest`.\n",
      " |      tolerance : float, optional\n",
      " |          The maximum error tolerance in input pixels when\n",
      " |          approximating the warp transformation. Default: 0.125,\n",
      " |          or one-eigth of a pixel.\n",
      " |      src_alpha : int, optional\n",
      " |          Index of a source band to use as an alpha band for warping.\n",
      " |      add_alpha : bool, optional\n",
      " |          Whether to add an alpha masking band to the virtual dataset.\n",
      " |          Default: False. This option will cause deletion of the VRT\n",
      " |          nodata value.\n",
      " |      init_dest_nodata : bool, optional\n",
      " |          Whether or not to initialize output to `nodata`. Default:\n",
      " |          True.\n",
      " |      warp_mem_limit : int, optional\n",
      " |          The warp operation's memory limit in MB. The default (0)\n",
      " |          means 64 MB with GDAL 2.2.\n",
      " |      dtype : str, optional\n",
      " |          The working data type for warp operation and output.\n",
      " |      warp_extras : dict\n",
      " |          GDAL extra warp options. See\n",
      " |          https://gdal.org/doxygen/structGDALWarpOptions.html.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      WarpedVRT\n",
      " |  \n",
      " |  __reduce__ = __reduce_cython__(...)\n",
      " |  \n",
      " |  __setstate__ = __setstate_cython__(...)\n",
      " |  \n",
      " |  read(...)\n",
      " |      Read a dataset's raw pixels as an N-d array\n",
      " |      \n",
      " |      This data is read from the dataset's band cache, which means\n",
      " |      that repeated reads of the same windows may avoid I/O.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indexes : list of ints or a single int, optional\n",
      " |          If `indexes` is a list, the result is a 3D array, but is\n",
      " |          a 2D array if it is a band index number.\n",
      " |      \n",
      " |      out : numpy ndarray, optional\n",
      " |          As with Numpy ufuncs, this is an optional reference to an\n",
      " |          output array into which data will be placed. If the height\n",
      " |          and width of `out` differ from that of the specified\n",
      " |          window (see below), the raster image will be decimated or\n",
      " |          replicated using the specified resampling method (also see\n",
      " |          below).\n",
      " |      \n",
      " |          *Note*: the method's return value may be a view on this\n",
      " |          array. In other words, `out` is likely to be an\n",
      " |          incomplete representation of the method's results.\n",
      " |      \n",
      " |          This parameter cannot be combined with `out_shape`.\n",
      " |      \n",
      " |      out_dtype : str or numpy dtype\n",
      " |          The desired output data type. For example: 'uint8' or\n",
      " |          rasterio.uint16.\n",
      " |      \n",
      " |      out_shape : tuple, optional\n",
      " |          A tuple describing the shape of a new output array. See\n",
      " |          `out` (above) for notes on image decimation and\n",
      " |          replication.\n",
      " |      \n",
      " |          Cannot combined with `out`.\n",
      " |      \n",
      " |      window : a pair (tuple) of pairs of ints or Window, optional\n",
      " |          The optional `window` argument is a 2 item tuple. The first\n",
      " |          item is a tuple containing the indexes of the rows at which\n",
      " |          the window starts and stops and the second is a tuple\n",
      " |          containing the indexes of the columns at which the window\n",
      " |          starts and stops. For example, ((0, 2), (0, 2)) defines\n",
      " |          a 2x2 window at the upper left of the raster dataset.\n",
      " |      \n",
      " |      masked : bool, optional\n",
      " |          If `masked` is `True` the return value will be a masked\n",
      " |          array. Otherwise (the default) the return value will be a\n",
      " |          regular array. Masks will be exactly the inverse of the\n",
      " |          GDAL RFC 15 conforming arrays returned by read_masks().\n",
      " |      \n",
      " |      resampling : Resampling\n",
      " |          By default, pixel values are read raw or interpolated using\n",
      " |          a nearest neighbor algorithm from the band cache. Other\n",
      " |          resampling algorithms may be specified. Resampled pixels\n",
      " |          are not cached.\n",
      " |      \n",
      " |      fill_value : scalar\n",
      " |          Fill value applied in the `boundless=True` case only.\n",
      " |      \n",
      " |      kwargs : dict\n",
      " |          This is only for backwards compatibility. No keyword arguments\n",
      " |          are supported other than the ones named above.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Numpy ndarray or a view on a Numpy ndarray\n",
      " |      \n",
      " |      Note: as with Numpy ufuncs, an object is returned even if you\n",
      " |      use the optional `out` argument and the return value shall be\n",
      " |      preferentially used by callers.\n",
      " |  \n",
      " |  read_masks(...)\n",
      " |      Read raster band masks as a multidimensional array\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from rasterio._warp.WarpedVRTReaderBase:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from rasterio._warp.WarpedVRTReaderBase:\n",
      " |  \n",
      " |  crs\n",
      " |      The dataset's coordinate reference system\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from rasterio._warp.WarpedVRTReaderBase:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from rasterio._io.DatasetReaderBase:\n",
      " |  \n",
      " |  dataset_mask(...)\n",
      " |      Get the dataset's 2D valid data mask.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      out : numpy ndarray, optional\n",
      " |          As with Numpy ufuncs, this is an optional reference to an\n",
      " |          output array with the same dimensions and shape into which\n",
      " |          data will be placed.\n",
      " |      \n",
      " |          *Note*: the method's return value may be a view on this\n",
      " |          array. In other words, `out` is likely to be an\n",
      " |          incomplete representation of the method's results.\n",
      " |      \n",
      " |          Cannot be combined with `out_shape`.\n",
      " |      \n",
      " |      out_shape : tuple, optional\n",
      " |          A tuple describing the output array's shape.  Allows for decimated\n",
      " |          reads without constructing an output Numpy array.\n",
      " |      \n",
      " |          Cannot be combined with `out`.\n",
      " |      \n",
      " |      window : a pair (tuple) of pairs of ints or Window, optional\n",
      " |          The optional `window` argument is a 2 item tuple. The first\n",
      " |          item is a tuple containing the indexes of the rows at which\n",
      " |          the window starts and stops and the second is a tuple\n",
      " |          containing the indexes of the columns at which the window\n",
      " |          starts and stops. For example, ((0, 2), (0, 2)) defines\n",
      " |          a 2x2 window at the upper left of the raster dataset.\n",
      " |      \n",
      " |      boundless : bool, optional (default `False`)\n",
      " |          If `True`, windows that extend beyond the dataset's extent\n",
      " |          are permitted and partially or completely filled arrays will\n",
      " |          be returned as appropriate.\n",
      " |      \n",
      " |      resampling : Resampling\n",
      " |          By default, pixel values are read raw or interpolated using\n",
      " |          a nearest neighbor algorithm from the band cache. Other\n",
      " |          resampling algorithms may be specified. Resampled pixels\n",
      " |          are not cached.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Numpy ndarray or a view on a Numpy ndarray\n",
      " |          The dtype of this array is uint8. 0 = nodata, 255 = valid\n",
      " |          data.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Note: as with Numpy ufuncs, an object is returned even if you\n",
      " |      use the optional `out` argument and the return value shall be\n",
      " |      preferentially used by callers.\n",
      " |      \n",
      " |      The dataset mask is calculated based on the individual band\n",
      " |      masks according to the following logic, in order of precedence:\n",
      " |      \n",
      " |      1. If a .msk file, dataset-wide alpha, or internal mask exists\n",
      " |         it will be used for the dataset mask.\n",
      " |      2. Else if the dataset is a 4-band  with a shadow nodata value, band 4 will be\n",
      " |         used as the dataset mask.\n",
      " |      3. If a nodata value exists, use the binary OR (|) of the band\n",
      " |         masks 4. If no nodata value exists, return a mask filled with\n",
      " |         255.\n",
      " |      \n",
      " |      Note that this differs from read_masks and GDAL RFC15 in that it\n",
      " |      applies per-dataset, not per-band (see\n",
      " |      https://trac.osgeo.org/gdal/wiki/rfc15_nodatabitmask)\n",
      " |  \n",
      " |  sample(...)\n",
      " |      Get the values of a dataset at certain positions\n",
      " |      \n",
      " |      Values are from the nearest pixel. They are not interpolated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      xy : iterable\n",
      " |          Pairs of x, y coordinates (floats) in the dataset's\n",
      " |          reference system.\n",
      " |      indexes : int or list of int\n",
      " |          Indexes of dataset bands to sample.\n",
      " |      masked : bool, default: False\n",
      " |          Whether to mask samples that fall outside the extent of the\n",
      " |          dataset.\n",
      " |      \n",
      " |      Returns\n",
      " |      ------\n",
      " |      iterable\n",
      " |          Arrays of length equal to the number of specified indexes\n",
      " |          containing the dataset values for the bands corresponding to\n",
      " |          those indexes.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from rasterio._base.DatasetBase:\n",
      " |  \n",
      " |  block_size(...)\n",
      " |      Returns the size in bytes of a particular block\n",
      " |      \n",
      " |      Only useful for TIFF formatted datasets.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bidx: int\n",
      " |          Band index, starting with 1.\n",
      " |      i: int\n",
      " |          Row index of the block, starting with 0.\n",
      " |      j: int\n",
      " |          Column index of the block, starting with 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  block_window(...)\n",
      " |      Returns the window for a particular block\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bidx: int\n",
      " |          Band index, starting with 1.\n",
      " |      i: int\n",
      " |          Row index of the block, starting with 0.\n",
      " |      j: int\n",
      " |          Column index of the block, starting with 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Window\n",
      " |  \n",
      " |  block_windows(...)\n",
      " |      Iterator over a band's blocks and their windows\n",
      " |      \n",
      " |      \n",
      " |      The primary use of this method is to obtain windows to pass to\n",
      " |      `read()` for highly efficient access to raster block data.\n",
      " |      \n",
      " |      The positional parameter `bidx` takes the index (starting at 1) of the\n",
      " |      desired band.  This iterator yields blocks \"left to right\" and \"top to\n",
      " |      bottom\" and is similar to Python's ``enumerate()`` in that the first\n",
      " |      element is the block index and the second is the dataset window.\n",
      " |      \n",
      " |      Blocks are built-in to a dataset and describe how pixels are grouped\n",
      " |      within each band and provide a mechanism for efficient I/O.  A window\n",
      " |      is a range of pixels within a single band defined by row start, row\n",
      " |      stop, column start, and column stop.  For example, ``((0, 2), (0, 2))``\n",
      " |      defines a ``2 x 2`` window at the upper left corner of a raster band.\n",
      " |      Blocks are referenced by an ``(i, j)`` tuple where ``(0, 0)`` would be\n",
      " |      a band's upper left block.\n",
      " |      \n",
      " |      Raster I/O is performed at the block level, so accessing a window\n",
      " |      spanning multiple rows in a striped raster requires reading each row.\n",
      " |      Accessing a ``2 x 2`` window at the center of a ``1800 x 3600`` image\n",
      " |      requires reading 2 rows, or 7200 pixels just to get the target 4.  The\n",
      " |      same image with internal ``256 x 256`` blocks would require reading at\n",
      " |      least 1 block (if the window entire window falls within a single block)\n",
      " |      and at most 4 blocks, or at least 512 pixels and at most 2048.\n",
      " |      \n",
      " |      Given an image that is ``512 x 512`` with blocks that are\n",
      " |      ``256 x 256``, its blocks and windows would look like::\n",
      " |      \n",
      " |          Blocks:\n",
      " |      \n",
      " |                  0       256     512\n",
      " |                0 +--------+--------+\n",
      " |                  |        |        |\n",
      " |                  | (0, 0) | (0, 1) |\n",
      " |                  |        |        |\n",
      " |              256 +--------+--------+\n",
      " |                  |        |        |\n",
      " |                  | (1, 0) | (1, 1) |\n",
      " |                  |        |        |\n",
      " |              512 +--------+--------+\n",
      " |      \n",
      " |      \n",
      " |          Windows:\n",
      " |      \n",
      " |              UL: ((0, 256), (0, 256))\n",
      " |              UR: ((0, 256), (256, 512))\n",
      " |              LL: ((256, 512), (0, 256))\n",
      " |              LR: ((256, 512), (256, 512))\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bidx : int, optional\n",
      " |          The band index (using 1-based indexing) from which to extract\n",
      " |          windows. A value less than 1 uses the first band if all bands have\n",
      " |          homogeneous windows and raises an exception otherwise.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      block, window\n",
      " |  \n",
      " |  checksum(...)\n",
      " |      Compute an integer checksum for the stored band\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bidx : int\n",
      " |          The band's index (1-indexed).\n",
      " |      window: tuple, optional\n",
      " |          A window of the band. Default is the entire extent of the band.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      An int.\n",
      " |  \n",
      " |  close(...)\n",
      " |      Close the dataset\n",
      " |  \n",
      " |  colormap(...)\n",
      " |      Returns a dict containing the colormap for a band or None.\n",
      " |  \n",
      " |  get_gcps(...)\n",
      " |      Get GCPs and their associated CRS.\n",
      " |  \n",
      " |  get_nodatavals(...)\n",
      " |  \n",
      " |  get_tag_item(...)\n",
      " |      Returns tag item value\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ns: str\n",
      " |          The key for the metadata item to fetch.\n",
      " |      dm: str\n",
      " |          The domain to fetch for.\n",
      " |      bidx: int\n",
      " |          Band index, starting with 1.\n",
      " |      ovr: int\n",
      " |          Overview level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |  \n",
      " |  get_transform(...)\n",
      " |      Returns a GDAL geotransform in its native form.\n",
      " |  \n",
      " |  lnglat(...)\n",
      " |  \n",
      " |  overviews(...)\n",
      " |  \n",
      " |  read_crs(...)\n",
      " |      Return the GDAL dataset's stored CRS\n",
      " |  \n",
      " |  read_transform(...)\n",
      " |      Return the stored GDAL GeoTransform\n",
      " |  \n",
      " |  start(...)\n",
      " |      Start the dataset's life cycle\n",
      " |  \n",
      " |  stop(...)\n",
      " |      Close the GDAL dataset handle\n",
      " |  \n",
      " |  tag_namespaces(...)\n",
      " |      Get a list of the dataset's metadata domains.\n",
      " |      \n",
      " |      Returned items may be passed as `ns` to the tags method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bidx int, optional\n",
      " |          Can be used to select a specific band, otherwise the\n",
      " |          dataset's general metadata domains are returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of str\n",
      " |  \n",
      " |  tags(...)\n",
      " |      Returns a dict containing copies of the dataset or band's\n",
      " |      tags.\n",
      " |      \n",
      " |      Tags are pairs of key and value strings. Tags belong to\n",
      " |      namespaces.  The standard namespaces are: default (None) and\n",
      " |      'IMAGE_STRUCTURE'.  Applications can create their own additional\n",
      " |      namespaces.\n",
      " |      \n",
      " |      The optional bidx argument can be used to select the tags of\n",
      " |      a specific band. The optional ns argument can be used to select\n",
      " |      a namespace other than the default.\n",
      " |  \n",
      " |  write_transform(...)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from rasterio._base.DatasetBase:\n",
      " |  \n",
      " |  block_shapes\n",
      " |      An ordered list of block shapes for each bands\n",
      " |      \n",
      " |      Shapes are tuples and have the same ordering as the dataset's\n",
      " |      shape: (count of image rows, count of image columns).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list\n",
      " |  \n",
      " |  bounds\n",
      " |      Returns the lower left and upper right bounds of the dataset\n",
      " |      in the units of its coordinate reference system.\n",
      " |      \n",
      " |      The returned value is a tuple:\n",
      " |      (lower left x, lower left y, upper right x, upper right y)\n",
      " |  \n",
      " |  closed\n",
      " |      Test if the dataset is closed\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  colorinterp\n",
      " |      Returns a sequence of ``ColorInterp.<enum>`` representing\n",
      " |      color interpretation in band order.\n",
      " |      \n",
      " |      To set color interpretation, provide a sequence of\n",
      " |      ``ColorInterp.<enum>``:\n",
      " |      \n",
      " |          import rasterio\n",
      " |          from rasterio.enums import ColorInterp\n",
      " |      \n",
      " |          with rasterio.open('rgba.tif', 'r+') as src:\n",
      " |              src.colorinterp = (\n",
      " |                  ColorInterp.red,\n",
      " |                  ColorInterp.green,\n",
      " |                  ColorInterp.blue,\n",
      " |                  ColorInterp.alpha)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple\n",
      " |  \n",
      " |  compression\n",
      " |  \n",
      " |  count\n",
      " |      The number of raster bands in the dataset\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |  \n",
      " |  descriptions\n",
      " |      Descriptions for each dataset band\n",
      " |      \n",
      " |      To set descriptions, one for each band is required.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of str\n",
      " |  \n",
      " |  driver\n",
      " |  \n",
      " |  dtypes\n",
      " |      The data types of each band in index order\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of str\n",
      " |  \n",
      " |  files\n",
      " |      Returns a sequence of files associated with the dataset.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple\n",
      " |  \n",
      " |  gcps\n",
      " |      ground control points and their coordinate reference system.\n",
      " |      \n",
      " |      This property is a 2-tuple, or pair: (gcps, crs).\n",
      " |      \n",
      " |      gcps : list of GroundControlPoint\n",
      " |          Zero or more ground control points.\n",
      " |      crs: CRS\n",
      " |          The coordinate reference system of the ground control points.\n",
      " |  \n",
      " |  height\n",
      " |  \n",
      " |  indexes\n",
      " |      The 1-based indexes of each band in the dataset\n",
      " |      \n",
      " |      For a 3-band dataset, this property will be ``[1, 2, 3]``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of int\n",
      " |  \n",
      " |  interleaving\n",
      " |  \n",
      " |  is_tiled\n",
      " |  \n",
      " |  mask_flag_enums\n",
      " |      Sets of flags describing the sources of band masks.\n",
      " |      \n",
      " |      all_valid: There are no invalid pixels, all mask values will be\n",
      " |          255. When used this will normally be the only flag set.\n",
      " |      per_dataset: The mask band is shared between all bands on the\n",
      " |          dataset.\n",
      " |      alpha: The mask band is actually an alpha band and may have\n",
      " |          values other than 0 and 255.\n",
      " |      nodata: Indicates the mask is actually being generated from\n",
      " |          nodata values (mutually exclusive of \"alpha\").\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list [, list*]\n",
      " |          One list of rasterio.enums.MaskFlags members per band.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For a 3 band dataset that has masks derived from nodata values:\n",
      " |      \n",
      " |      >>> dataset.mask_flag_enums\n",
      " |      ([<MaskFlags.nodata: 8>], [<MaskFlags.nodata: 8>], [<MaskFlags.nodata: 8>])\n",
      " |      >>> band1_flags = dataset.mask_flag_enums[0]\n",
      " |      >>> rasterio.enums.MaskFlags.nodata in band1_flags\n",
      " |      True\n",
      " |      >>> rasterio.enums.MaskFlags.alpha in band1_flags\n",
      " |      False\n",
      " |  \n",
      " |  meta\n",
      " |      The basic metadata of this dataset.\n",
      " |  \n",
      " |  mode\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  nodata\n",
      " |      The dataset's single nodata value\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      May be set.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |  \n",
      " |  nodatavals\n",
      " |      Nodata values for each band\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This may not be set.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of float\n",
      " |  \n",
      " |  offsets\n",
      " |      Raster offset for each dataset band\n",
      " |      \n",
      " |      To set offsets, one for each band is required.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of float\n",
      " |  \n",
      " |  options\n",
      " |  \n",
      " |  photometric\n",
      " |  \n",
      " |  profile\n",
      " |      Basic metadata and creation options of this dataset.\n",
      " |      \n",
      " |      May be passed as keyword arguments to `rasterio.open()` to\n",
      " |      create a clone of this dataset.\n",
      " |  \n",
      " |  res\n",
      " |      Returns the (width, height) of pixels in the units of its\n",
      " |      coordinate reference system.\n",
      " |  \n",
      " |  rpcs\n",
      " |      Rational polynomial coefficients mapping between pixel and geodetic coordinates.\n",
      " |      \n",
      " |      This property is a dict-like object.\n",
      " |      \n",
      " |      rpcs : RPC instance containing coefficients. Empty if dataset does not have any\n",
      " |      metadata in the \"RPC\" domain.\n",
      " |  \n",
      " |  scales\n",
      " |      Raster scale for each dataset band\n",
      " |      \n",
      " |      To set scales, one for each band is required.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of float\n",
      " |  \n",
      " |  shape\n",
      " |  \n",
      " |  subdatasets\n",
      " |      Sequence of subdatasets\n",
      " |  \n",
      " |  transform\n",
      " |      The dataset's georeferencing transformation matrix\n",
      " |      \n",
      " |      This transform maps pixel row/column coordinates to coordinates\n",
      " |      in the dataset's coordinate reference system.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Affine\n",
      " |  \n",
      " |  units\n",
      " |      A list of str: one units string for each dataset band\n",
      " |      \n",
      " |      Possible values include 'meters' or 'degC'. See the Pint\n",
      " |      project for a suggested list of units.\n",
      " |      \n",
      " |      To set units, one for each band is required.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of str\n",
      " |  \n",
      " |  width\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from rasterio.windows.WindowMethodsMixin:\n",
      " |  \n",
      " |  window(self, left, bottom, right, top, precision=None)\n",
      " |      Get the window corresponding to the bounding coordinates.\n",
      " |      \n",
      " |      The resulting window is not cropped to the row and column\n",
      " |      limits of the dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left: float\n",
      " |          Left (west) bounding coordinate\n",
      " |      bottom: float\n",
      " |          Bottom (south) bounding coordinate\n",
      " |      right: float\n",
      " |          Right (east) bounding coordinate\n",
      " |      top: float\n",
      " |          Top (north) bounding coordinate\n",
      " |      precision: int, optional\n",
      " |          Number of decimal points of precision when computing inverse\n",
      " |          transform.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      window: Window\n",
      " |  \n",
      " |  window_bounds(self, window)\n",
      " |      Get the bounds of a window\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window: rasterio.windows.Window\n",
      " |          Dataset window\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bounds : tuple\n",
      " |          x_min, y_min, x_max, y_max for the given window\n",
      " |  \n",
      " |  window_transform(self, window)\n",
      " |      Get the affine transform for a dataset window.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window: rasterio.windows.Window\n",
      " |          Dataset window\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      transform: Affine\n",
      " |          The affine transform matrix for the given window\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from rasterio.transform.TransformMethodsMixin:\n",
      " |  \n",
      " |  index(self, x, y, op=<built-in function floor>, precision=None)\n",
      " |      Returns the (row, col) index of the pixel containing (x, y) given a\n",
      " |      coordinate reference system.\n",
      " |      \n",
      " |      Use an epsilon, magnitude determined by the precision parameter\n",
      " |      and sign determined by the op function:\n",
      " |          positive for floor, negative for ceil.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : float\n",
      " |          x value in coordinate reference system\n",
      " |      y : float\n",
      " |          y value in coordinate reference system\n",
      " |      op : function, optional (default: math.floor)\n",
      " |          Function to convert fractional pixels to whole numbers (floor,\n",
      " |          ceiling, round)\n",
      " |      precision : int, optional (default: None)\n",
      " |          Decimal places of precision in indexing, as in `round()`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple\n",
      " |          (row index, col index)\n",
      " |  \n",
      " |  xy(self, row, col, offset='center')\n",
      " |      Returns the coordinates ``(x, y)`` of a pixel at `row` and `col`.\n",
      " |      The pixel's center is returned by default, but a corner can be returned\n",
      " |      by setting `offset` to one of `ul, ur, ll, lr`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      row : int\n",
      " |          Pixel row.\n",
      " |      col : int\n",
      " |          Pixel column.\n",
      " |      offset : str, optional\n",
      " |          Determines if the returned coordinates are for the center of the\n",
      " |          pixel or for a corner.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple\n",
      " |          ``(x, y)``\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WarpedVRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test.tif': [{'window_id': 1,\n",
       "   'polygon_coords': [(-11169700.787427548, -4193553.7119406024),\n",
       "    (-11169700.787427548, -4191764.5839900365),\n",
       "    (-11171489.915378114, -4191764.5839900365),\n",
       "    (-11171489.915378114, -4193553.7119406024),\n",
       "    (-11169700.787427548, -4193553.7119406024)],\n",
       "   'labels': []},\n",
       "  {'window_id': 2,\n",
       "   'polygon_coords': [(-11167911.659476982, -4193553.7119406024),\n",
       "    (-11167911.659476982, -4191764.5839900365),\n",
       "    (-11169700.787427548, -4191764.5839900365),\n",
       "    (-11169700.787427548, -4193553.7119406024),\n",
       "    (-11167911.659476982, -4193553.7119406024)],\n",
       "   'labels': []},\n",
       "  {'window_id': 3,\n",
       "   'polygon_coords': [(-11166122.531526417, -4193553.7119406024),\n",
       "    (-11166122.531526417, -4191764.5839900365),\n",
       "    (-11167911.659476982, -4191764.5839900365),\n",
       "    (-11167911.659476982, -4193553.7119406024),\n",
       "    (-11166122.531526417, -4193553.7119406024)],\n",
       "   'labels': []},\n",
       "  {'window_id': 4,\n",
       "   'polygon_coords': [(-11164333.40357585, -4193553.7119406024),\n",
       "    (-11164333.40357585, -4191764.5839900365),\n",
       "    (-11166122.531526417, -4191764.5839900365),\n",
       "    (-11166122.531526417, -4193553.7119406024),\n",
       "    (-11164333.40357585, -4193553.7119406024)],\n",
       "   'labels': []},\n",
       "  {'window_id': 5,\n",
       "   'polygon_coords': [(-11162544.275625283, -4193553.7119406024),\n",
       "    (-11162544.275625283, -4191764.5839900365),\n",
       "    (-11164333.40357585, -4191764.5839900365),\n",
       "    (-11164333.40357585, -4193553.7119406024),\n",
       "    (-11162544.275625283, -4193553.7119406024)],\n",
       "   'labels': []},\n",
       "  {'window_id': 6,\n",
       "   'polygon_coords': [(-11160755.147674717, -4193553.7119406024),\n",
       "    (-11160755.147674717, -4191764.5839900365),\n",
       "    (-11162544.275625283, -4191764.5839900365),\n",
       "    (-11162544.275625283, -4193553.7119406024),\n",
       "    (-11160755.147674717, -4193553.7119406024)],\n",
       "   'labels': []},\n",
       "  {'window_id': 7,\n",
       "   'polygon_coords': [(-11158966.019724151, -4193553.7119406024),\n",
       "    (-11158966.019724151, -4191764.5839900365),\n",
       "    (-11160755.147674717, -4191764.5839900365),\n",
       "    (-11160755.147674717, -4193553.7119406024),\n",
       "    (-11158966.019724151, -4193553.7119406024)],\n",
       "   'labels': []},\n",
       "  {'window_id': 8,\n",
       "   'polygon_coords': [(-11157176.891773585, -4193553.7119406024),\n",
       "    (-11157176.891773585, -4191764.5839900365),\n",
       "    (-11158966.019724151, -4191764.5839900365),\n",
       "    (-11158966.019724151, -4193553.7119406024),\n",
       "    (-11157176.891773585, -4193553.7119406024)],\n",
       "   'labels': []},\n",
       "  {'window_id': 9,\n",
       "   'polygon_coords': [(-11155387.76382302, -4193553.7119406024),\n",
       "    (-11155387.76382302, -4191764.5839900365),\n",
       "    (-11157176.891773585, -4191764.5839900365),\n",
       "    (-11157176.891773585, -4193553.7119406024),\n",
       "    (-11155387.76382302, -4193553.7119406024)],\n",
       "   'labels': []},\n",
       "  {'window_id': 10,\n",
       "   'polygon_coords': [(-11153598.635872453, -4193553.7119406024),\n",
       "    (-11153598.635872453, -4191764.5839900365),\n",
       "    (-11155387.76382302, -4191764.5839900365),\n",
       "    (-11155387.76382302, -4193553.7119406024),\n",
       "    (-11153598.635872453, -4193553.7119406024)],\n",
       "   'labels': []}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = output_dict\n",
    "\n",
    "count = {}\n",
    "label_match_results = []\n",
    "granule_count = len(data.keys())\n",
    "granule_list = data.keys()\n",
    "count[\"granule_count\"] = granule_count\n",
    "for k1 in list(data.keys()):\n",
    "    for i in range(len(data[k1])):\n",
    "        if len(data[k1][i]['labels']) == 0:\n",
    "            if \"null_chips\" not in count.keys():\n",
    "                count[\"null_chips\"] = 1\n",
    "            else:\n",
    "                count[\"null_chips\"] += 1 \n",
    "        for label in data[k1][i]['labels']:\n",
    "            if label not in count.keys():\n",
    "                count[label] = 1 \n",
    "            else:\n",
    "                    count[label] += 1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'granule_count': 1,\n",
       " 'null_chips': 1512,\n",
       " 'Shifting_cultivation': 336,\n",
       " 'ISL': 82,\n",
       " 'Roads': 5,\n",
       " 'Industrial_agriculture': 1}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(output_dict['101'])):\n",
    "    print(output_dict['101'][i]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdf.to_file(\"./inference_output/test.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\"./inference_output/test.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output_files(json_path,download=True, filepath = \"predict_test-2021-05-10-22-38-41.json\", label_match=\"Shifting_cultivation\"):\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "\n",
    "    #Download Model, Weights\n",
    "    \n",
    "    if download:\n",
    "        \n",
    "        bucket = json_path.split(\"/\")[2]\n",
    "        model_key = \"/\".join(json_path.split(\"/\")[3:])\n",
    "        filename = json_path.split(\"/\")[-1]\n",
    "        s3.Bucket(bucket).download_file(model_key, filename )\n",
    "        filepath = filename\n",
    "    \n",
    "    with open(filepath) as jsonfile:\n",
    "        data = json.load(jsonfile)\n",
    "        \n",
    "\n",
    "    count = {}\n",
    "    label_match_results = []\n",
    "    granule_count = len(data.keys())\n",
    "    granule_list = data.keys()\n",
    "    count[\"granule_count\"] = granule_count\n",
    "    for k1 in list(data.keys()):\n",
    "        for i in range(len(data[k1])):\n",
    "            if len(data[k1][i]['labels']) == 0:\n",
    "                if \"null_chips\" not in count.keys():\n",
    "                    count[\"null_chips\"] = 1\n",
    "                else:\n",
    "                    count[\"null_chips\"] += 1 \n",
    "            for label in data[k1][i]['labels']:\n",
    "                if label == label_match:\n",
    "                    label_match_results.append([k1,data[k1][i]])\n",
    "                if label not in count.keys():\n",
    "                    count[label] = 1 \n",
    "                else:\n",
    "                    count[label] += 1 \n",
    "    return count, label_match_results, granule_list, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"s3://canopy-production-ml/inference/output/predict_test-2021-05-10-22-38-41.json\"\n",
    "\n",
    "count, match_results, granule_list, data = process_output_files(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'granule_count': 692,\n",
       " 'null_chips': 529984,\n",
       " 'ISL': 25994,\n",
       " 'Shifting_cultivation': 188801,\n",
       " 'Mining': 1232,\n",
       " 'Roads': 14003,\n",
       " 'Industrial_agriculture': 8940}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_list = []\n",
    "for result in match_results:\n",
    "    coords = result[1][\"polygon_coords\"]\n",
    "    polygon = Polygon(coords)\n",
    "    polygon_list.append(polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame({\"geometry\":polygon_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gdf.set_crs(epsg=3257)\n",
    "        \n",
    "# gdf = gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((21.46111 0.77255, 21.46111 0.78153, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((21.68569 0.77255, 21.68569 0.78153, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((21.46111 0.76357, 21.46111 0.77255, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((21.64976 0.76357, 21.64976 0.77255, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((21.43416 0.75458, 21.43416 0.76357, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134081</th>\n",
       "      <td>POLYGON ((17.31503 0.50306, 17.31503 0.51204, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134082</th>\n",
       "      <td>POLYGON ((17.34198 0.50306, 17.34198 0.51204, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134083</th>\n",
       "      <td>POLYGON ((17.28808 0.49407, 17.28808 0.50306, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134084</th>\n",
       "      <td>POLYGON ((17.29706 0.49407, 17.29706 0.50306, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134085</th>\n",
       "      <td>POLYGON ((17.34198 0.49407, 17.34198 0.50306, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134086 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 geometry\n",
       "0       POLYGON ((21.46111 0.77255, 21.46111 0.78153, ...\n",
       "1       POLYGON ((21.68569 0.77255, 21.68569 0.78153, ...\n",
       "2       POLYGON ((21.46111 0.76357, 21.46111 0.77255, ...\n",
       "3       POLYGON ((21.64976 0.76357, 21.64976 0.77255, ...\n",
       "4       POLYGON ((21.43416 0.75458, 21.43416 0.76357, ...\n",
       "...                                                   ...\n",
       "134081  POLYGON ((17.31503 0.50306, 17.31503 0.51204, ...\n",
       "134082  POLYGON ((17.34198 0.50306, 17.34198 0.51204, ...\n",
       "134083  POLYGON ((17.28808 0.49407, 17.28808 0.50306, ...\n",
       "134084  POLYGON ((17.29706 0.49407, 17.29706 0.50306, ...\n",
       "134085  POLYGON ((17.34198 0.49407, 17.34198 0.50306, ...\n",
       "\n",
       "[134086 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\"./inference_output/test_roads.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-11169700.787427548, -4193553.7119406024],\n",
       " [-11169700.787427548, -4191764.5839900365],\n",
       " [-11171489.915378114, -4191764.5839900365],\n",
       " [-11171489.915378114, -4193553.7119406024],\n",
       " [-11169700.787427548, -4193553.7119406024]]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['test.tif'][0][\"polygon_coords\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Vectorized Predicted Granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_dir_match(s3_dir_url,granule_list):\n",
    "    \n",
    "\n",
    "    objs = []\n",
    "    bucket = s3_dir_url.split(\"/\")[2]\n",
    "    key = \"/\".join(s3_dir_url.split(\"/\")[3:5])\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "\n",
    "    window_geom_list = []\n",
    "    granule_id_list = []\n",
    "    for obj in my_bucket.objects.filter(Prefix=key):\n",
    "        granule_id = obj.key.split(\"/\")[-1].split(\"_\")[0]\n",
    "        if granule_id in granule_list:\n",
    "            obj_url = \"s3://\" + bucket + \"/\" + obj.key\n",
    "            with rio.open(obj_url) as src:\n",
    "                bounds = src.bounds\n",
    "                geom = box(*bounds)\n",
    "                window_geom_list.append(geom)\n",
    "                granule_id_list.append(granule_id)\n",
    "    gdf = gpd.GeoDataFrame({\"geometry\":window_geom_list,\"granule_id\":granule_id_list})\n",
    "                \n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = s3_dir_match(\"s3://canopy-production-ml/full_congo_basin/02.17.21_CB_GEE_Pull/\",granule_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\"granules.json\", driver=\"GeoJSON\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Export GDF of Original Labels Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"/Users/purgatorid/Downloads/polygons_021521.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    FILE_NAME)\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    crs={'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = []\n",
    "for polygon in df[\"polygon\"]:\n",
    "    polygons.append(Polygon(json.loads(polygon)[\"coordinates\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"geometry\"] = polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.loc[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(\"output.json\", driver=\"GeoJSON\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Reproject One Granulate Containing ISL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_raster(input_file, dest_dir, epsg_format='EPSG:3257', windows=False):\n",
    "    \"\"\"Converts the rasters in the src_dir into a different EPSG format,\n",
    "    keeping the same folder structure and saving them in the dest_dir.\"\"\"\n",
    "    \n",
    "    print(input_file)\n",
    "\n",
    "    filename = \"test.tif\"\n",
    "#     print(filename)\n",
    "\n",
    "    # If the respective grouping folders are not available \n",
    "\n",
    "    output_filepath = dest_dir + filename\n",
    "    print(output_filepath)\n",
    "\n",
    "\n",
    "#         Finally, we convert\n",
    "    converted = gdal.Warp(output_filepath, [input_file],format='GTiff',\n",
    "                          dstSRS=epsg_format, resampleAlg='near')\n",
    "    converted = None\n",
    "        \n",
    "    print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "granule = \"/Users/purgatorid/Downloads/1241_full_congo_export_v12_all_bands_Feb_11_12_44_53_2021.tif\"\n",
    "dest_dir = \"/Users/purgatorid/Downloads/\"\n",
    "\n",
    "convert_raster(granule,dest_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results (Incomplete Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(match_results,s3_url):\n",
    "    for window in match_results:\n",
    "        granule_id = window[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {1,2,4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Without Windows Code - Direct Chip Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_predictions(granule_dir,patch_size=100,\n",
    "                   stride=100,SAVE=False,SAVE_INDIVIDUAL=False,\n",
    "                   bands=[2, 3, 4, 8, 11, 12], \n",
    "                  model=model,\n",
    "                   predict_thresh=.5,\n",
    "                  label_list=label_list, \n",
    "                  job_name=\"test_inference\", \n",
    "                  output_filename=\"./inference_output/result.json\", \n",
    "                      apply_windows=False, \n",
    "                      read_process=\"read_img_tf_out\", \n",
    "                      sample_frac=1):\n",
    "    \n",
    "    granule_list = glob(f'{granule_dir}/*.tif')\n",
    "    \n",
    "    end = len(granule_list) // sample_frac \n",
    "    \n",
    "    granule_list = granule_list[0:end]\n",
    "    \n",
    "    print(f\"running inference on {len(granule_list)} chips\")\n",
    "    \n",
    "    output_dict = {}\n",
    "    \n",
    "    granule_id_list = []\n",
    "    \n",
    "    window_id_list = []\n",
    "    \n",
    "    window_geom_list = []\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    label_master_list = []\n",
    "    \n",
    "    gdf_list = []\n",
    "    \n",
    "    timestamp = gen_timestamp()\n",
    "    \n",
    "    missed_chips = []\n",
    "    \n",
    "    for j,granule_path in enumerate(granule_list):\n",
    "        \n",
    "        print(f'running inference on {j} of {len(granule_list)}',end='\\r', flush=True)\n",
    "        \n",
    "        label_name_list = []\n",
    "        \n",
    "        granule_id = granule_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "        filepath = granule_path.split(\"/\")[-1]\n",
    "        \n",
    "        if filepath:\n",
    "\n",
    "            with rio.open(granule_path) as src:\n",
    "\n",
    "                data = src.read(bands,masked=True)\n",
    "\n",
    "                data = add_ndvi(data)\n",
    "\n",
    "                shape = data.shape\n",
    "\n",
    "                if apply_windows:\n",
    "\n",
    "                    new_shape = (data.shape[0],patch_size,patch_size)\n",
    "\n",
    "                    if shape != new_shape:\n",
    "\n",
    "                        filled_array = np.full(new_shape, 0)\n",
    "                        filled_array[:shape[0],:shape[1],:shape[2]] = data\n",
    "                        data = filled_array\n",
    "                        window = Window(window.col_off,window.row_off,shape[2],shape[1])\n",
    "\n",
    "                #image pre-processing / inference\n",
    "\n",
    "\n",
    "                if read_process == \"read_img_tf_out\":\n",
    "                    read_func = read_image_tf_out\n",
    "                else:\n",
    "                    read_func = read_image\n",
    "\n",
    "                prediction = model.predict(read_func(data))\n",
    "#                 print(\"original_prediction:\",prediction)\n",
    "                prediction = np.where(prediction > predict_thresh, 1, 0)\n",
    "#                 print(\"sigmoid prediction gate:\",prediction)\n",
    "                prediction_i = np.where(prediction == 1)[1]\n",
    "                if 1 not in np.where(prediction == 1)[1]:\n",
    "                    missed_chips.append(granule_path)\n",
    "#                 print(\"index of matching labels:\",prediction_i)\n",
    "                for i in prediction_i:\n",
    "                    label_name_list.append(label_list[i])\n",
    "\n",
    "                label_master_list.append(label_name_list)\n",
    "\n",
    "                #vectorizing raster bounds for visualization \n",
    "                data_bounds = src.bounds\n",
    "                geom = box(*data_bounds)\n",
    "                geom_coords = list(geom.exterior.coords)\n",
    "    #                 window_geom_list.append(geom)\n",
    "\n",
    "                #create or append to dict....\n",
    "\n",
    "                if granule_id in output_dict:\n",
    "\n",
    "                    output_dict[granule_id].append({\"polygon_coords\":geom_coords,\"labels\":label_name_list})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    output_dict[granule_id] = [{\"polygon_coords\":geom_coords,\"labels\":label_name_list}]\n",
    "\n",
    "        save_to_s3(output_dict,output_filename,job_name,timestamp)\n",
    "\n",
    "\n",
    "\n",
    "    #             gdf = gpd.GeoDataFrame({\"granule_id\":granule_id_list,\"window_id\":window_id_list,\"geometry\":window_geom_list,\"labels\":label_master_list})\n",
    "    #             gdf[\"labels\"] = gdf[\"labels\"].astype(str)\n",
    "\n",
    "    #             gdf_list.append(gdf)\n",
    "\n",
    "    return output_dict,missed_chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running inference on 75 chips\n",
      "running inference on 74 of 75\r"
     ]
    }
   ],
   "source": [
    "# granule_dir = \"./efs_inference_data/\"\n",
    "granule_dir_local = \"/Volumes/Lacie/zhenyadata/Project_Canopy_Data/PC_Data/Sentinel_Data/Chips/misha_polygons_cloudfreemerge/yes/ISL/100/91/\"\n",
    "# granule_dir_efs = \n",
    "\n",
    "output_dict,missed_chips = output_predictions(granule_dir_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"file_path\":missed_chips})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"missed_chips.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = output_dict\n",
    "\n",
    "count = {}\n",
    "label_match_results = []\n",
    "granule_count = len(data.keys())\n",
    "granule_list = data.keys()\n",
    "count[\"granule_count\"] = granule_count\n",
    "for k1 in list(data.keys()):\n",
    "    for i in range(len(data[k1])):\n",
    "        if len(data[k1][i]['labels']) == 0:\n",
    "            if \"null_chips\" not in count.keys():\n",
    "                count[\"null_chips\"] = 1\n",
    "            else:\n",
    "                count[\"null_chips\"] += 1 \n",
    "        for label in data[k1][i]['labels']:\n",
    "            if label not in count.keys():\n",
    "                count[label] = 1 \n",
    "            else:\n",
    "                    count[label] += 1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'granule_count': 1,\n",
       " 'ISL': 43,\n",
       " 'Shifting_cultivation': 24,\n",
       " 'Roads': 3,\n",
       " 'null_chips': 3,\n",
       " 'Industrial_agriculture': 2}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram for Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_hist(arr,tensor=True):\n",
    "    \n",
    "    if tensor:\n",
    "        arr = np.array(arr)\n",
    "        arr = np.transpose(arr[0], (2, 1, 0))\n",
    "\n",
    "\n",
    "    for i in range(arr.shape[0]):\n",
    "        band_np = arr[i].flatten()\n",
    "        plt.hist(band_np,label=str(i))\n",
    "\n",
    "\n",
    "    plt.legend(prop={'size': 10})\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_hist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_hist(data1,tensor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer-conda",
   "language": "python",
   "name": "infer-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
