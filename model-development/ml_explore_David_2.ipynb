{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with Simple CNN and Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation enabled \n",
      "Training on 200 images \n",
      "Validation on 366 images \n",
      "Your training file is missing positive labels for classes ['0', '2', '3', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "gen = DataLoader(label_file_path_train=\"labels_test_v1.csv\",\n",
    "                label_file_path_val=\"val_labels.csv\",\n",
    "                label_mapping_path=\"labels.json\",\n",
    "                bucket_name='canopy-production-ml',\n",
    "                data_extension_type='.tif',\n",
    "                training_data_shape=(100, 100, 18),\n",
    "                augment=True,\n",
    "                random_flip_up_down=False, #Randomly flips an image vertically (upside down). With a 1 in 2 chance, outputs the contents of `image` flipped along the first dimension, which is `height`.\n",
    "                random_flip_left_right=False,\n",
    "                flip_left_right=False,\n",
    "                flip_up_down=False,\n",
    "                rot90=True,\n",
    "                transpose=False,\n",
    "                enable_shuffle=False,\n",
    "                training_data_shuffle_buffer_size=10,\n",
    "                training_data_batch_size=batch_size,\n",
    "                training_data_type=tf.float32,\n",
    "                label_data_type=tf.uint8,\n",
    "                num_parallel_calls=int(2))\n",
    "# TODO add data augmentation in DataLoader \n",
    "\n",
    "# no_of_val_imgs = len(gen.validation_filenames)\n",
    "# no_of_train_imgs = len(gen.training_filenames)\n",
    "# print(\"Validation on {} images \".format(str(no_of_val_imgs)))\n",
    "# print(\"Training on {} images \".format(str(no_of_train_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_loader.DataLoader at 0x155732b90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.76875, 4: 0.4270833333333333, 5: 10.25, 6: 3.84375}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "95    1\n",
       "96    1\n",
       "97    1\n",
       "98    0\n",
       "99    0\n",
       "Name: 1, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing positive chips for class 0\n",
      "Missing positive chips for class 2\n",
      "Missing positive chips for class 3\n",
      "Missing positive chips for class 7\n",
      "Missing positive chips for class 8\n",
      "Missing positive chips for class 9\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    \n",
    "    col_count = df[column].value_counts()\n",
    "#     print(\"column:\",column)\n",
    "#     print(col_count)\n",
    "    \n",
    "    try:\n",
    "        col_count = df[column].value_counts()[1]\n",
    "        labels[column] = col_count\n",
    "    except:\n",
    "        print(f\"Missing positive chips for class {column}. Class weight \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 40, '4': 72, '5': 3, '6': 8, 'paths': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 86s 18s/step - loss: 8.7035 - val_loss: 1.5012\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 81s 17s/step - loss: 1.4694 - val_loss: 0.8578\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.6244 - val_loss: 0.2065\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 86s 17s/step - loss: 0.1674 - val_loss: 0.2439\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 84s 17s/step - loss: 0.1836 - val_loss: 0.2107\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 87s 18s/step - loss: 0.1562 - val_loss: 0.1956\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.1483 - val_loss: 0.1829\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.1326 - val_loss: 0.1831\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 87s 17s/step - loss: 0.1373 - val_loss: 0.1843\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.1324 - val_loss: 0.1902\n"
     ]
    }
   ],
   "source": [
    "def Simple_CNN(numclasses, input_shape): #TODO use a more complex CNN\n",
    "        model = Sequential([\n",
    "            layers.Input(input_shape),\n",
    "            layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(numclasses)\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "model_simpleCNN = Simple_CNN(10, input_shape=(100, 100, 18))\n",
    "callbacks_list = []\n",
    "\n",
    "model_simpleCNN.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "          optimizer=keras.optimizers.Adam()) #TODO add callbacks to save checkpoints and maybe lr reducer,etc \n",
    "\n",
    "epochs = 10\n",
    "history = model_simpleCNN.fit(gen.training_dataset, validation_data=gen.validation_dataset, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 18)\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "obj = s3.Object('canopy-production-ml', \"chips/cloudfree-merge-polygons/split/test/100/100_1000_1000.tif\")\n",
    "obj_bytes = io.BytesIO(obj.get()['Body'].read())\n",
    "with rasterio.open(obj_bytes) as src:\n",
    "    img_test = np.transpose(src.read(), (1, 2, 0))\n",
    "print(img_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['Habitation', 'ISL', 'Industrial_agriculture', 'Mining',\n",
    "    'Rainforest', 'River', 'Roads', 'Savannah', 'Shifting_cultivation',\n",
    "    'Water'\n",
    "]\n",
    "# TODO Need to weight labels since they are pretty unbalanced (Rainforest is largely represented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 = boto3.resource('s3')\n",
    "# obj = s3.Object('canopy-production-ml', \"chips/cloudfree-merge-polygons/split/train/58/58_1300_1000.tif\")\n",
    "# obj_bytes = io.BytesIO(obj.get()['Body'].read())\n",
    "# with rasterio.open(obj_bytes) as src:\n",
    "#     img_test = np.transpose(src.read(), (1, 2, 0)) / 255\n",
    "# print(img_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This chip was predicted to belong to class Rainforest\n"
     ]
    }
   ],
   "source": [
    "predictions = model_simpleCNN.predict(np.array([img_test]))\n",
    "highest_score_predictions = np.argmax(predictions) # TODO: read more about multi classes PER IMAGE classification, what is the threshold?\n",
    "\n",
    "print(\"This chip was predicted to belong to class {}\".format(label_list[highest_score_predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2020.7277        4.4248075 -1614.4033    -3687.283       157.33759\n",
      "  -1660.8308     -644.8952    -2039.6393    -1582.1956    -1557.5543   ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 7, 0, 5, 2, 8, 9, 6, 1, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predictions)\n",
    "predictions.argsort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 35s 10s/step - loss: 0.1902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19022126495838165"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simpleCNN.evaluate(gen.validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resnet50(numclasses, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(keras.applications.ResNet50(include_top=False, pooling='avg', weights=None, input_shape=input_shape))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(numclasses, activation='softmax'))\n",
    "    model.layers[0].trainable = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 18 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 100s 19s/step - loss: 0.7197 - val_loss: 0.7552\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 92s 18s/step - loss: 0.7108 - val_loss: 0.7552\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 89s 18s/step - loss: 0.6910 - val_loss: 0.7552\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 92s 18s/step - loss: 0.6992 - val_loss: 0.7552\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 88s 18s/step - loss: 0.6945 - val_loss: 0.7552\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 90s 17s/step - loss: 0.6954 - val_loss: 0.7552\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 91s 18s/step - loss: 0.6927 - val_loss: 0.7552\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 90s 17s/step - loss: 0.6903 - val_loss: 0.7552\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 91s 19s/step - loss: 0.6820 - val_loss: 0.7552\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 94s 18s/step - loss: 0.6781 - val_loss: 0.7552\n"
     ]
    }
   ],
   "source": [
    "model_resnet50 = Resnet50(10, input_shape=(100, 100, 18))\n",
    "callbacks_list = []\n",
    "\n",
    "model_resnet50.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "          optimizer=keras.optimizers.Adam()) #TODO add callbacks to save checkpoints and maybe lr reducer, earlystop,etc \n",
    "\n",
    "epochs = 10\n",
    "history = model_resnet50.fit(gen.training_dataset, validation_data=gen.validation_dataset, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This chip was predicted to belong to class Industrial_agriculture\n"
     ]
    }
   ],
   "source": [
    "predictions = model_resnet50.predict(np.array([img_test]))\n",
    "highest_score_predictions = np.argmax(predictions) # TODO: read more about multi classes PER IMAGE classification, what is the threshold?\n",
    "\n",
    "print(\"This chip was predicted to belong to class {}\".format(label_list[highest_score_predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 29s 9s/step - loss: 0.7552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7551586031913757"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resnet50.evaluate(gen.validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industrial_agriculture\n",
      "Water\n",
      "Shifting_cultivation\n"
     ]
    }
   ],
   "source": [
    "# https://kgptalkie.com/multi-label-image-classification-on-movies-poster-using-cnn/\n",
    "top3 = np.argsort(predictions[0])[:-4:-1]\n",
    "for i in range(3):\n",
    "  print(label_list[top3[i]]) # We need to define a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learningCurve(history, epoch):\n",
    "  # Plot training & validation accuracy values\n",
    "#   plt.plot(history.history['accuracy'])\n",
    "#   plt.plot(history.history['val_accuracy'])\n",
    "#   plt.title('Model accuracy')\n",
    "#   plt.ylabel('Accuracy')\n",
    "#   plt.xlabel('Epoch')\n",
    "#   plt.legend(['Train', 'Val'], loc='upper left')\n",
    "#   plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "plot_learningCurve(history, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medium_CNN(numclasses, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), activation='relu', input_shape = input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    model.add(Dense(numclasses, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 86s 17s/step - loss: 0.9270 - accuracy: 0.1209 - val_loss: 0.8956 - val_accuracy: 0.1200\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 91s 19s/step - loss: 0.9144 - accuracy: 0.1223 - val_loss: 0.9091 - val_accuracy: 0.1200\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 85s 17s/step - loss: 0.9159 - accuracy: 0.1198 - val_loss: 0.9205 - val_accuracy: 0.1200\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 86s 18s/step - loss: 0.9162 - accuracy: 0.1193 - val_loss: 0.9494 - val_accuracy: 0.1200\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 84s 17s/step - loss: 0.9036 - accuracy: 0.1200 - val_loss: 0.9662 - val_accuracy: 0.1200\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 85s 17s/step - loss: 0.9077 - accuracy: 0.1201 - val_loss: 0.9763 - val_accuracy: 0.1200\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 89s 17s/step - loss: 0.9053 - accuracy: 0.1200 - val_loss: 0.9755 - val_accuracy: 0.1200\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 84s 17s/step - loss: 0.8920 - accuracy: 0.1197 - val_loss: 0.9652 - val_accuracy: 0.1200\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 85s 17s/step - loss: 0.8925 - accuracy: 0.1195 - val_loss: 0.9509 - val_accuracy: 0.1200\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 84s 17s/step - loss: 0.8863 - accuracy: 0.1211 - val_loss: 0.9204 - val_accuracy: 0.1200\n"
     ]
    }
   ],
   "source": [
    "model_medium_CNN = medium_CNN(10, input_shape=(100, 100, 18))\n",
    "callbacks_list = []\n",
    "\n",
    "model_medium_CNN.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                          optimizer=keras.optimizers.Adam(),\n",
    "                          metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')]) #TODO add callbacks to save checkpoints and maybe lr reducer, earlystop,etc \n",
    "\n",
    "epochs = 10\n",
    "history = model_medium_CNN.fit(gen.training_dataset, validation_data=gen.validation_dataset, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This chip was predicted to belong to top 3 classes:\n",
      "Water\n",
      "Shifting_cultivation\n",
      "Savannah\n"
     ]
    }
   ],
   "source": [
    "predictions = model_medium_CNN.predict(np.array([img_test]))\n",
    "highest_score_predictions = np.argmax(predictions) # TODO: read more about multi classes PER IMAGE classification, what is the threshold?\n",
    "\n",
    "print(\"This chip was predicted to belong to top 3 classes:\")\n",
    "\n",
    "top3 = np.argsort(predictions[0])[:-4:-1]\n",
    "for i in range(3):\n",
    "  print(label_list[top3[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 32s 11s/step - loss: 0.9204 - accuracy: 0.1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9204237461090088, 0.12000000476837158]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_medium_CNN.evaluate(gen.validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learningCurve(history, epoch):\n",
    "  # Plot training & validation accuracy values\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "plot_learningCurve(history, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST with bigearthnet-resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py:228 call  *\n        result = f()\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1669 __call__  **\n        return self._call_impl(args, kwargs)\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/wrap_function.py:246 _call_impl\n        return super(WrappedFunction, self)._call_impl(\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1687 _call_impl\n        return self._call_with_flat_signature(args, kwargs, cancellation_manager)\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1736 _call_with_flat_signature\n        return self._call_flat(args, self.captured_inputs, cancellation_manager)\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1900 _call_flat\n        raise ValueError(\n\n    ValueError: The argument 'images' (value Tensor(\"Placeholder:0\", shape=(None, 100, 100, 4), dtype=float32)) is not compatible with the shape this function was traced with. Expected shape (None, None, None, 3), but got shape (None, 100, 100, 4).\n    \n    If you called get_concrete_function, you may need to pass a tf.TensorSpec(..., shape=...) with a less specific shape, having None on axes which can vary.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9359f750e35b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://tfhub.dev/google/remote_sensing/bigearthnet-resnet50/1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m model_bigearthnet = tf.keras.Sequential([\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# reshape?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow_hub/keras_layer.py:228 call  *\n        result = f()\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1669 __call__  **\n        return self._call_impl(args, kwargs)\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/wrap_function.py:246 _call_impl\n        return super(WrappedFunction, self)._call_impl(\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1687 _call_impl\n        return self._call_with_flat_signature(args, kwargs, cancellation_manager)\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1736 _call_with_flat_signature\n        return self._call_flat(args, self.captured_inputs, cancellation_manager)\n    /usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1900 _call_flat\n        raise ValueError(\n\n    ValueError: The argument 'images' (value Tensor(\"Placeholder:0\", shape=(None, 100, 100, 4), dtype=float32)) is not compatible with the shape this function was traced with. Expected shape (None, None, None, 3), but got shape (None, 100, 100, 4).\n    \n    If you called get_concrete_function, you may need to pass a tf.TensorSpec(..., shape=...) with a less specific shape, having None on axes which can vary.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "IMAGE_SIZE = (100,100)\n",
    "num_classes = 10\n",
    "model_handle = \"https://tfhub.dev/google/remote_sensing/bigearthnet-resnet50/1\"\n",
    "model_bigearthnet = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    # reshape? \n",
    "    hub.KerasLayer(model_handle, trainable=False, input_shape=IMAGE_SIZE + (3,)),\n",
    "#     (model.layers[-1].output)\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(num_classes,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "model_bigearthnet.build((None,)+IMAGE_SIZE+(4,))\n",
    "model_bigearthnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_bigearthnet.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#           optimizer=keras.optimizers.Adam()) #TODO add callbacks to save checkpoints and maybe lr reducer, earlystop,etc \n",
    "\n",
    "# epochs = 10\n",
    "# history = model_bigearthnet.fit(gen.training_dataset, validation_data=gen.validation_dataset, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model_resnet50.predict(np.array([img_test]))\n",
    "# highest_score_predictions = np.argmax(predictions) # TODO: read more about multi classes PER IMAGE classification, what is the threshold?\n",
    "\n",
    "# print(\"This chip was predicted to belong to class {}\".format(label_list[highest_score_predictions]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproduction Candidate: ResNet50 pretrained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation on 55 images \n",
      "Training on 100 images \n"
     ]
    }
   ],
   "source": [
    "gen = DataLoader(label_file_path_train=\"labels_test_v1.csv\", #or labels.csv\n",
    "                        label_file_path_val=\"val_labels.csv\",\n",
    "                        bucket_name='canopy-production-ml',\n",
    "                        data_extension_type='.tif',\n",
    "                        training_data_shape=(100, 100, 18),\n",
    "                        shuffle_and_repeat=False,\n",
    "                        enable_just_shuffle=False,\n",
    "                        enable_just_repeat=False,\n",
    "                        training_data_shuffle_buffer_size=10,\n",
    "                        data_repeat_count=None,\n",
    "                        training_data_batch_size=20,\n",
    "                        normalization_value=255.0,  #normalization TODO double check other channels than RGB \n",
    "                        training_data_type=tf.float32,\n",
    "                        label_data_type=tf.uint8,\n",
    "                        enable_data_prefetch=False,\n",
    "                        data_prefetch_size=tf.data.experimental.AUTOTUNE,\n",
    "                        num_parallel_calls=int(2))\n",
    "# TODO add data augmentation in DataLoader \n",
    "\n",
    "no_of_val_imgs = len(gen.validation_filenames)\n",
    "no_of_train_imgs = len(gen.training_filenames)\n",
    "print(\"Validation on {} images \".format(str(no_of_val_imgs)))\n",
    "print(\"Training on {} images \".format(str(no_of_train_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(numclasses,input_shape):\n",
    "    # parameters for CNN\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # introduce a additional layer to get from bands to 3 input channels\n",
    "    input_tensor = Conv2D(3, (1, 1))(input_tensor)\n",
    "\n",
    "    base_model_resnet50 = keras.applications.ResNet50(include_top=False,\n",
    "                              weights='imagenet',\n",
    "                              input_shape=(100, 100, 3))\n",
    "    base_model = keras.applications.ResNet50(include_top=False,\n",
    "                     weights=None,\n",
    "                     input_tensor=input_tensor)\n",
    "\n",
    "    for i, layer in enumerate(base_model_resnet50.layers):\n",
    "        # we must skip input layer, which has no weights\n",
    "        if i == 0:\n",
    "            continue\n",
    "        base_model.layers[i+1].set_weights(layer.get_weights())\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    top_model = base_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "    # and a logistic layer\n",
    "    predictions = Dense(numclasses, activation='softmax')(top_model)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 18 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 100, 100, 3)  57          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 106, 106, 3)  0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 50, 50, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 50, 50, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 52, 52, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 25, 25, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 25, 25, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 25, 25, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 25, 25, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 25, 25, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 25, 25, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 25, 25, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 25, 25, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 25, 25, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 25, 25, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 25, 25, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 25, 25, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 25, 25, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 25, 25, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 25, 25, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 13, 13, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 13, 13, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 13, 13, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 13, 13, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 13, 13, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 13, 13, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 13, 13, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 13, 13, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 13, 13, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 13, 13, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 13, 13, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 13, 13, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 13, 13, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 13, 13, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 13, 13, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 13, 13, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 13, 13, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 13, 13, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 7, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 7, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 7, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 7, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 7, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 7, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 7, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 7, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 7, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 7, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 7, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 7, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 7, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 7, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 7, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 7, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 7, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 7, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 7, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 7, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 7, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 7, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         4196352     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         4196352     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20490       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 32,000,963\n",
      "Trainable params: 31,947,843\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random_id = 5555 #TODO\n",
    "checkpoint_file = 'checkpoint_{}.h5'.format(random_id)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "  filepath= checkpoint_file,\n",
    "  format='h5',\n",
    "  verbose=1,\n",
    "  save_weights_only=True,\n",
    "  monitor='val_loss',\n",
    "  mode='min',\n",
    "  save_best_only=True)\n",
    "\n",
    "reducelronplateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "  monitor='val_loss', factor=0.1, patience=10, verbose=1,\n",
    "  mode='min', min_lr=1e-10)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min', patience=20, verbose=1)\n",
    "\n",
    "callbacks_list = [model_checkpoint_callback, reducelronplateau, early_stop]\n",
    "\n",
    "model = define_model(10, (100,100,18))\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                          optimizer=keras.optimizers.Adam(),\n",
    "                          metrics=[tf.metrics.BinaryAccuracy(name='accuracy')]) #TODO add callbacks to save checkpoints and maybe lr reducer, earlystop,etc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "      1/Unknown - 0s 0s/step - loss: 0.7377 - accuracy: 0.8900"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2fbc1874cc41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m history = model.fit(gen.training_dataset, validation_data=gen.validation_dataset, \n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                     callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(gen.training_dataset, validation_data=gen.validation_dataset, \n",
    "                    epochs=epochs, \n",
    "                    callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 9s 3s/step - loss: 0.6661 - accuracy: 0.9473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6660677194595337, 0.9472727179527283]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(gen.validation_dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on BatchDataset in module tensorflow.python.data.ops.dataset_ops object:\n",
      "\n",
      "class BatchDataset(UnaryDataset)\n",
      " |  BatchDataset(input_dataset, batch_size, drop_remainder)\n",
      " |  \n",
      " |  A `Dataset` that batches contiguous elements from its input.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BatchDataset\n",
      " |      UnaryDataset\n",
      " |      DatasetV2\n",
      " |      collections.abc.Iterable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input_dataset, batch_size, drop_remainder)\n",
      " |      See `Dataset.batch()` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  element_spec\n",
      " |      The type specification of an element of this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset.element_spec\n",
      " |      TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        A nested structure of `tf.TypeSpec` objects matching the structure of an\n",
      " |        element of this dataset and specifying the type of individual components.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from DatasetV2:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Creates an iterator for elements of this dataset.\n",
      " |      \n",
      " |      The returned iterator implements the Python Iterator protocol.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An `tf.data.Iterator` for the elements of this dataset.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If not inside of tf.function and not executing eagerly.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the length of the dataset if it is known and finite.\n",
      " |      \n",
      " |      This method requires that you are running in eager mode, and that the\n",
      " |      length of the dataset is known and non-infinite. When the length may be\n",
      " |      unknown or infinite, or if you are running in graph mode, use\n",
      " |      `tf.data.Dataset.cardinality` instead.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An integer representing the length of the dataset.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the dataset length is unknown or infinite, or if eager\n",
      " |          execution is not enabled.\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  apply(self, transformation_func)\n",
      " |      Applies a transformation function to this dataset.\n",
      " |      \n",
      " |      `apply` enables chaining of custom `Dataset` transformations, which are\n",
      " |      represented as functions that take one `Dataset` argument and return a\n",
      " |      transformed `Dataset`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(100)\n",
      " |      >>> def dataset_fn(ds):\n",
      " |      ...   return ds.filter(lambda x: x < 5)\n",
      " |      >>> dataset = dataset.apply(dataset_fn)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Args:\n",
      " |        transformation_func: A function that takes one `Dataset` argument and\n",
      " |          returns a `Dataset`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: The `Dataset` returned by applying `transformation_func` to this\n",
      " |            dataset.\n",
      " |  \n",
      " |  as_numpy_iterator(self)\n",
      " |      Returns an iterator which converts all elements of the dataset to numpy.\n",
      " |      \n",
      " |      Use `as_numpy_iterator` to inspect the content of your dataset. To see\n",
      " |      element shapes and types, print dataset elements directly instead of using\n",
      " |      `as_numpy_iterator`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> for element in dataset:\n",
      " |      ...   print(element)\n",
      " |      tf.Tensor(1, shape=(), dtype=int32)\n",
      " |      tf.Tensor(2, shape=(), dtype=int32)\n",
      " |      tf.Tensor(3, shape=(), dtype=int32)\n",
      " |      \n",
      " |      This method requires that you are running in eager mode and the dataset's\n",
      " |      element_spec contains only `TensorSpec` components.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      1\n",
      " |      2\n",
      " |      3\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> print(list(dataset.as_numpy_iterator()))\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      `as_numpy_iterator()` will preserve the nested structure of dataset\n",
      " |      elements.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]),\n",
      " |      ...                                               'b': [5, 6]})\n",
      " |      >>> list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5},\n",
      " |      ...                                       {'a': (2, 4), 'b': 6}]\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        An iterable over the elements of the dataset, with their tensors converted\n",
      " |        to numpy arrays.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: if an element contains a non-`Tensor` value.\n",
      " |        RuntimeError: if eager execution is not enabled.\n",
      " |  \n",
      " |  batch(self, batch_size, drop_remainder=False)\n",
      " |      Combines consecutive elements of this dataset into batches.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(8)\n",
      " |      >>> dataset = dataset.batch(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(8)\n",
      " |      >>> dataset = dataset.batch(3, drop_remainder=True)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([0, 1, 2]), array([3, 4, 5])]\n",
      " |      \n",
      " |      The components of the resulting element will have an additional outer\n",
      " |      dimension, which will be `batch_size` (or `N % batch_size` for the last\n",
      " |      element if `batch_size` does not divide the number of input elements `N`\n",
      " |      evenly and `drop_remainder` is `False`). If your program depends on the\n",
      " |      batches having the same outer dimension, you should set the `drop_remainder`\n",
      " |      argument to `True` to prevent the smaller batch from being produced.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements of this dataset to combine in a single batch.\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  cache(self, filename='')\n",
      " |      Caches the elements in this dataset.\n",
      " |      \n",
      " |      The first time the dataset is iterated over, its elements will be cached\n",
      " |      either in the specified file or in memory. Subsequent iterations will\n",
      " |      use the cached data.\n",
      " |      \n",
      " |      Note: For the cache to be finalized, the input dataset must be iterated\n",
      " |      through in its entirety. Otherwise, subsequent iterations will not use\n",
      " |      cached data.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(5)\n",
      " |      >>> dataset = dataset.map(lambda x: x**2)\n",
      " |      >>> dataset = dataset.cache()\n",
      " |      >>> # The first time reading through the data will generate the data using\n",
      " |      >>> # `range` and `map`.\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 4, 9, 16]\n",
      " |      >>> # Subsequent iterations read from the cache.\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 4, 9, 16]\n",
      " |      \n",
      " |      When caching to a file, the cached data will persist across runs. Even the\n",
      " |      first iteration through the data will read from the cache file. Changing\n",
      " |      the input pipeline before the call to `.cache()` will have no effect until\n",
      " |      the cache file is removed or the filename is changed.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(5)\n",
      " |      >>> dataset = dataset.cache(\"/path/to/file\")  # doctest: +SKIP\n",
      " |      >>> list(dataset.as_numpy_iterator())  # doctest: +SKIP\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.cache(\"/path/to/file\")  # Same file! # doctest: +SKIP\n",
      " |      >>> list(dataset.as_numpy_iterator())  # doctest: +SKIP\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Note: `cache` will produce exactly the same elements during each iteration\n",
      " |      through the dataset. If you wish to randomize the iteration order, make sure\n",
      " |      to call `shuffle` *after* calling `cache`.\n",
      " |      \n",
      " |      Args:\n",
      " |        filename: A `tf.string` scalar `tf.Tensor`, representing the name of a\n",
      " |          directory on the filesystem to use for caching elements in this Dataset.\n",
      " |          If a filename is not provided, the dataset will be cached in memory.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  cardinality(self)\n",
      " |      Returns the cardinality of the dataset, if known.\n",
      " |      \n",
      " |      `cardinality` may return `tf.data.INFINITE_CARDINALITY` if the dataset\n",
      " |      contains an infinite number of elements or `tf.data.UNKNOWN_CARDINALITY` if\n",
      " |      the analysis fails to determine the number of elements in the dataset\n",
      " |      (e.g. when the dataset source is a file).\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(42)\n",
      " |      >>> print(dataset.cardinality().numpy())\n",
      " |      42\n",
      " |      >>> dataset = dataset.repeat()\n",
      " |      >>> cardinality = dataset.cardinality()\n",
      " |      >>> print((cardinality == tf.data.INFINITE_CARDINALITY).numpy())\n",
      " |      True\n",
      " |      >>> dataset = dataset.filter(lambda x: True)\n",
      " |      >>> cardinality = dataset.cardinality()\n",
      " |      >>> print((cardinality == tf.data.UNKNOWN_CARDINALITY).numpy())\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A scalar `tf.int64` `Tensor` representing the cardinality of the dataset.\n",
      " |        If the cardinality is infinite or unknown, `cardinality` returns the\n",
      " |        named constants `tf.data.INFINITE_CARDINALITY` and\n",
      " |        `tf.data.UNKNOWN_CARDINALITY` respectively.\n",
      " |  \n",
      " |  concatenate(self, dataset)\n",
      " |      Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
      " |      \n",
      " |      >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
      " |      >>> b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ]\n",
      " |      >>> ds = a.concatenate(b)\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [1, 2, 3, 4, 5, 6, 7]\n",
      " |      >>> # The input dataset and dataset to be concatenated should have the same\n",
      " |      >>> # nested structures and output types.\n",
      " |      >>> c = tf.data.Dataset.zip((a, b))\n",
      " |      >>> a.concatenate(c)\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Two datasets to concatenate have different types\n",
      " |      <dtype: 'int64'> and (tf.int64, tf.int64)\n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices([\"a\", \"b\", \"c\"])\n",
      " |      >>> a.concatenate(d)\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Two datasets to concatenate have different types\n",
      " |      <dtype: 'int64'> and <dtype: 'string'>\n",
      " |      \n",
      " |      Args:\n",
      " |        dataset: `Dataset` to be concatenated.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  enumerate(self, start=0)\n",
      " |      Enumerates the elements of this dataset.\n",
      " |      \n",
      " |      It is similar to python's `enumerate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.enumerate(start=5)\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (5, 1)\n",
      " |      (6, 2)\n",
      " |      (7, 3)\n",
      " |      \n",
      " |      >>> # The nested structure of the input dataset determines the structure of\n",
      " |      >>> # elements in the resulting dataset.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)])\n",
      " |      >>> dataset = dataset.enumerate()\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (0, array([7, 8], dtype=int32))\n",
      " |      (1, array([ 9, 10], dtype=int32))\n",
      " |      \n",
      " |      Args:\n",
      " |        start: A `tf.int64` scalar `tf.Tensor`, representing the start value for\n",
      " |          enumeration.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  filter(self, predicate)\n",
      " |      Filters this dataset according to `predicate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.filter(lambda x: x < 3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2]\n",
      " |      >>> # `tf.math.equal(x, y)` is required for equality comparison\n",
      " |      >>> def filter_fn(x):\n",
      " |      ...   return tf.math.equal(x, 1)\n",
      " |      >>> dataset = dataset.filter(filter_fn)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1]\n",
      " |      \n",
      " |      Args:\n",
      " |        predicate: A function mapping a dataset element to a boolean.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: The `Dataset` containing the elements of this dataset for which\n",
      " |            `predicate` is `True`.\n",
      " |  \n",
      " |  flat_map(self, map_func)\n",
      " |      Maps `map_func` across this dataset and flattens the result.\n",
      " |      \n",
      " |      Use `flat_map` if you want to make sure that the order of your dataset\n",
      " |      stays the same. For example, to flatten a dataset of batches into a\n",
      " |      dataset of their elements:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(\n",
      " |      ...                [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      " |      >>> dataset = dataset.flat_map(lambda x: Dataset.from_tensor_slices(x))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      " |      \n",
      " |      `tf.data.Dataset.interleave()` is a generalization of `flat_map`, since\n",
      " |      `flat_map` produces the same output as\n",
      " |      `tf.data.Dataset.interleave(cycle_length=1)`\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function mapping a dataset element to a dataset.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  interleave(self, map_func, cycle_length=None, block_length=None, num_parallel_calls=None, deterministic=None)\n",
      " |      Maps `map_func` across this dataset, and interleaves the results.\n",
      " |      \n",
      " |      For example, you can use `Dataset.interleave()` to process many input files\n",
      " |      concurrently:\n",
      " |      \n",
      " |      >>> # Preprocess 4 files concurrently, and interleave blocks of 16 records\n",
      " |      >>> # from each file.\n",
      " |      >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
      " |      ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
      " |      >>> def parse_fn(filename):\n",
      " |      ...   return tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.interleave(lambda x:\n",
      " |      ...     tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1),\n",
      " |      ...     cycle_length=4, block_length=16)\n",
      " |      \n",
      " |      The `cycle_length` and `block_length` arguments control the order in which\n",
      " |      elements are produced. `cycle_length` controls the number of input elements\n",
      " |      that are processed concurrently. If you set `cycle_length` to 1, this\n",
      " |      transformation will handle one input element at a time, and will produce\n",
      " |      identical results to `tf.data.Dataset.flat_map`. In general,\n",
      " |      this transformation will apply `map_func` to `cycle_length` input elements,\n",
      " |      open iterators on the returned `Dataset` objects, and cycle through them\n",
      " |      producing `block_length` consecutive elements from each iterator, and\n",
      " |      consuming the next input element each time it reaches the end of an\n",
      " |      iterator.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> # NOTE: New lines indicate \"block\" boundaries.\n",
      " |      >>> dataset = dataset.interleave(\n",
      " |      ...     lambda x: Dataset.from_tensors(x).repeat(6),\n",
      " |      ...     cycle_length=2, block_length=4)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 1, 1, 1,\n",
      " |       2, 2, 2, 2,\n",
      " |       1, 1,\n",
      " |       2, 2,\n",
      " |       3, 3, 3, 3,\n",
      " |       4, 4, 4, 4,\n",
      " |       3, 3,\n",
      " |       4, 4,\n",
      " |       5, 5, 5, 5,\n",
      " |       5, 5]\n",
      " |      \n",
      " |      Note: The order of elements yielded by this transformation is\n",
      " |      deterministic, as long as `map_func` is a pure function and\n",
      " |      `deterministic=True`. If `map_func` contains any stateful operations, the\n",
      " |      order in which that state is accessed is undefined.\n",
      " |      \n",
      " |      Performance can often be improved by setting `num_parallel_calls` so that\n",
      " |      `interleave` will use multiple threads to fetch elements. If determinism\n",
      " |      isn't required, it can also improve performance to set\n",
      " |      `deterministic=False`.\n",
      " |      \n",
      " |      >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
      " |      ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
      " |      >>> dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x),\n",
      " |      ...     cycle_length=4, num_parallel_calls=tf.data.AUTOTUNE,\n",
      " |      ...     deterministic=False)\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function mapping a dataset element to a dataset.\n",
      " |        cycle_length: (Optional.) The number of input elements that will be\n",
      " |          processed concurrently. If not set, the tf.data runtime decides what it\n",
      " |          should be based on available CPU. If `num_parallel_calls` is set to\n",
      " |          `tf.data.AUTOTUNE`, the `cycle_length` argument identifies\n",
      " |          the maximum degree of parallelism.\n",
      " |        block_length: (Optional.) The number of consecutive elements to produce\n",
      " |          from each input element before cycling to another input element. If not\n",
      " |          set, defaults to 1.\n",
      " |        num_parallel_calls: (Optional.) If specified, the implementation creates a\n",
      " |          threadpool, which is used to fetch inputs from cycle elements\n",
      " |          asynchronously and in parallel. The default behavior is to fetch inputs\n",
      " |          from cycle elements synchronously with no parallelism. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available CPU.\n",
      " |        deterministic: (Optional.) A boolean controlling whether determinism\n",
      " |          should be traded for performance by allowing elements to be produced out\n",
      " |          of order.  If `deterministic` is `None`, the\n",
      " |          `tf.data.Options.experimental_deterministic` dataset option (`True` by\n",
      " |          default) is used to decide whether to produce elements\n",
      " |          deterministically.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  map(self, map_func, num_parallel_calls=None, deterministic=None)\n",
      " |      Maps `map_func` across the elements of this dataset.\n",
      " |      \n",
      " |      This transformation applies `map_func` to each element of this dataset, and\n",
      " |      returns a new dataset containing the transformed elements, in the same\n",
      " |      order as they appeared in the input. `map_func` can be used to change both\n",
      " |      the values and the structure of a dataset's elements. For example, adding 1\n",
      " |      to each element, or projecting a subset of element components.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> dataset = dataset.map(lambda x: x + 1)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [2, 3, 4, 5, 6]\n",
      " |      \n",
      " |      The input signature of `map_func` is determined by the structure of each\n",
      " |      element in this dataset.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(5)\n",
      " |      >>> # `map_func` takes a single argument of type `tf.Tensor` with the same\n",
      " |      >>> # shape and dtype.\n",
      " |      >>> result = dataset.map(lambda x: x + 1)\n",
      " |      \n",
      " |      >>> # Each element is a tuple containing two `tf.Tensor` objects.\n",
      " |      >>> elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz\")]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, (tf.int32, tf.string))\n",
      " |      >>> # `map_func` takes two arguments of type `tf.Tensor`. This function\n",
      " |      >>> # projects out just the first component.\n",
      " |      >>> result = dataset.map(lambda x_int, y_str: x_int)\n",
      " |      >>> list(result.as_numpy_iterator())\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      >>> # Each element is a dictionary mapping strings to `tf.Tensor` objects.\n",
      " |      >>> elements =  ([{\"a\": 1, \"b\": \"foo\"},\n",
      " |      ...               {\"a\": 2, \"b\": \"bar\"},\n",
      " |      ...               {\"a\": 3, \"b\": \"baz\"}])\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, {\"a\": tf.int32, \"b\": tf.string})\n",
      " |      >>> # `map_func` takes a single argument of type `dict` with the same keys\n",
      " |      >>> # as the elements.\n",
      " |      >>> result = dataset.map(lambda d: str(d[\"a\"]) + d[\"b\"])\n",
      " |      \n",
      " |      The value or values returned by `map_func` determine the structure of each\n",
      " |      element in the returned dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> # `map_func` returns two `tf.Tensor` objects.\n",
      " |      >>> def g(x):\n",
      " |      ...   return tf.constant(37.0), tf.constant([\"Foo\", \"Bar\", \"Baz\"])\n",
      " |      >>> result = dataset.map(g)\n",
      " |      >>> result.element_spec\n",
      " |      (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(3,), dtype=tf.string, name=None))\n",
      " |      >>> # Python primitives, lists, and NumPy arrays are implicitly converted to\n",
      " |      >>> # `tf.Tensor`.\n",
      " |      >>> def h(x):\n",
      " |      ...   return 37.0, [\"Foo\", \"Bar\"], np.array([1.0, 2.0], dtype=np.float64)\n",
      " |      >>> result = dataset.map(h)\n",
      " |      >>> result.element_spec\n",
      " |      (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.string, name=None), TensorSpec(shape=(2,), dtype=tf.float64, name=None))\n",
      " |      >>> # `map_func` can return nested structures.\n",
      " |      >>> def i(x):\n",
      " |      ...   return (37.0, [42, 16]), \"foo\"\n",
      " |      >>> result = dataset.map(i)\n",
      " |      >>> result.element_spec\n",
      " |      ((TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
      " |        TensorSpec(shape=(2,), dtype=tf.int32, name=None)),\n",
      " |       TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      " |      \n",
      " |      `map_func` can accept as arguments and return any type of dataset element.\n",
      " |      \n",
      " |      Note that irrespective of the context in which `map_func` is defined (eager\n",
      " |      vs. graph), tf.data traces the function and executes it as a graph. To use\n",
      " |      Python code inside of the function you have a few options:\n",
      " |      \n",
      " |      1) Rely on AutoGraph to convert Python code into an equivalent graph\n",
      " |      computation. The downside of this approach is that AutoGraph can convert\n",
      " |      some but not all Python code.\n",
      " |      \n",
      " |      2) Use `tf.py_function`, which allows you to write arbitrary Python code but\n",
      " |      will generally result in worse performance than 1). For example:\n",
      " |      \n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
      " |      >>> # transform a string tensor to upper case string using a Python function\n",
      " |      >>> def upper_case_fn(t: tf.Tensor):\n",
      " |      ...   return t.numpy().decode('utf-8').upper()\n",
      " |      >>> d = d.map(lambda x: tf.py_function(func=upper_case_fn,\n",
      " |      ...           inp=[x], Tout=tf.string))\n",
      " |      >>> list(d.as_numpy_iterator())\n",
      " |      [b'HELLO', b'WORLD']\n",
      " |      \n",
      " |      3) Use `tf.numpy_function`, which also allows you to write arbitrary\n",
      " |      Python code. Note that `tf.py_function` accepts `tf.Tensor` whereas\n",
      " |      `tf.numpy_function` accepts numpy arrays and returns only numpy arrays.\n",
      " |      For example:\n",
      " |      \n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
      " |      >>> def upper_case_fn(t: np.ndarray):\n",
      " |      ...   return t.decode('utf-8').upper()\n",
      " |      >>> d = d.map(lambda x: tf.numpy_function(func=upper_case_fn,\n",
      " |      ...           inp=[x], Tout=tf.string))\n",
      " |      >>> list(d.as_numpy_iterator())\n",
      " |      [b'HELLO', b'WORLD']\n",
      " |      \n",
      " |      Note that the use of `tf.numpy_function` and `tf.py_function`\n",
      " |      in general precludes the possibility of executing user-defined\n",
      " |      transformations in parallel (because of Python GIL).\n",
      " |      \n",
      " |      Performance can often be improved by setting `num_parallel_calls` so that\n",
      " |      `map` will use multiple threads to process elements. If deterministic order\n",
      " |      isn't required, it can also improve performance to set\n",
      " |      `deterministic=False`.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> dataset = dataset.map(lambda x: x + 1,\n",
      " |      ...     num_parallel_calls=tf.data.AUTOTUNE,\n",
      " |      ...     deterministic=False)\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function mapping a dataset element to another dataset element.\n",
      " |        num_parallel_calls: (Optional.) A `tf.int32` scalar `tf.Tensor`,\n",
      " |          representing the number elements to process asynchronously in parallel.\n",
      " |          If not specified, elements will be processed sequentially. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available CPU.\n",
      " |        deterministic: (Optional.) A boolean controlling whether determinism\n",
      " |          should be traded for performance by allowing elements to be produced out\n",
      " |          of order.  If `deterministic` is `None`, the\n",
      " |          `tf.data.Options.experimental_deterministic` dataset option (`True` by\n",
      " |          default) is used to decide whether to produce elements\n",
      " |          deterministically.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  options(self)\n",
      " |      Returns the options for this dataset and its inputs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.data.Options` object representing the dataset options.\n",
      " |  \n",
      " |  padded_batch(self, batch_size, padded_shapes=None, padding_values=None, drop_remainder=False)\n",
      " |      Combines consecutive elements of this dataset into padded batches.\n",
      " |      \n",
      " |      This transformation combines multiple consecutive elements of the input\n",
      " |      dataset into a single element.\n",
      " |      \n",
      " |      Like `tf.data.Dataset.batch`, the components of the resulting element will\n",
      " |      have an additional outer dimension, which will be `batch_size` (or\n",
      " |      `N % batch_size` for the last element if `batch_size` does not divide the\n",
      " |      number of input elements `N` evenly and `drop_remainder` is `False`). If\n",
      " |      your program depends on the batches having the same outer dimension, you\n",
      " |      should set the `drop_remainder` argument to `True` to prevent the smaller\n",
      " |      batch from being produced.\n",
      " |      \n",
      " |      Unlike `tf.data.Dataset.batch`, the input elements to be batched may have\n",
      " |      different shapes, and this transformation will pad each component to the\n",
      " |      respective shape in `padded_shapes`. The `padded_shapes` argument\n",
      " |      determines the resulting shape for each dimension of each component in an\n",
      " |      output element:\n",
      " |      \n",
      " |      * If the dimension is a constant, the component will be padded out to that\n",
      " |        length in that dimension.\n",
      " |      * If the dimension is unknown, the component will be padded out to the\n",
      " |        maximum length of all elements in that dimension.\n",
      " |      \n",
      " |      >>> A = (tf.data.Dataset\n",
      " |      ...      .range(1, 5, output_type=tf.int32)\n",
      " |      ...      .map(lambda x: tf.fill([x], x)))\n",
      " |      >>> # Pad to the smallest per-batch size that fits all elements.\n",
      " |      >>> B = A.padded_batch(2)\n",
      " |      >>> for element in B.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[1 0]\n",
      " |       [2 2]]\n",
      " |      [[3 3 3 0]\n",
      " |       [4 4 4 4]]\n",
      " |      >>> # Pad to a fixed size.\n",
      " |      >>> C = A.padded_batch(2, padded_shapes=5)\n",
      " |      >>> for element in C.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[1 0 0 0 0]\n",
      " |       [2 2 0 0 0]]\n",
      " |      [[3 3 3 0 0]\n",
      " |       [4 4 4 4 0]]\n",
      " |      >>> # Pad with a custom value.\n",
      " |      >>> D = A.padded_batch(2, padded_shapes=5, padding_values=-1)\n",
      " |      >>> for element in D.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[ 1 -1 -1 -1 -1]\n",
      " |       [ 2  2 -1 -1 -1]]\n",
      " |      [[ 3  3  3 -1 -1]\n",
      " |       [ 4  4  4  4 -1]]\n",
      " |      >>> # Components of nested elements can be padded independently.\n",
      " |      >>> elements = [([1, 2, 3], [10]),\n",
      " |      ...             ([4, 5], [11, 12])]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: iter(elements), (tf.int32, tf.int32))\n",
      " |      >>> # Pad the first component of the tuple to length 4, and the second\n",
      " |      >>> # component to the smallest size that fits.\n",
      " |      >>> dataset = dataset.padded_batch(2,\n",
      " |      ...     padded_shapes=([4], [None]),\n",
      " |      ...     padding_values=(-1, 100))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(array([[ 1,  2,  3, -1], [ 4,  5, -1, -1]], dtype=int32),\n",
      " |        array([[ 10, 100], [ 11,  12]], dtype=int32))]\n",
      " |      >>> # Pad with a single value and multiple components.\n",
      " |      >>> E = tf.data.Dataset.zip((A, A)).padded_batch(2, padding_values=-1)\n",
      " |      >>> for element in E.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (array([[ 1, -1],\n",
      " |             [ 2,  2]], dtype=int32), array([[ 1, -1],\n",
      " |             [ 2,  2]], dtype=int32))\n",
      " |      (array([[ 3,  3,  3, -1],\n",
      " |             [ 4,  4,  4,  4]], dtype=int32), array([[ 3,  3,  3, -1],\n",
      " |             [ 4,  4,  4,  4]], dtype=int32))\n",
      " |      \n",
      " |      See also `tf.data.experimental.dense_to_sparse_batch`, which combines\n",
      " |      elements that may have different shapes into a `tf.sparse.SparseTensor`.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements of this dataset to combine in a single batch.\n",
      " |        padded_shapes: (Optional.) A nested structure of `tf.TensorShape` or\n",
      " |          `tf.int64` vector tensor-like objects representing the shape to which\n",
      " |          the respective component of each input element should be padded prior\n",
      " |          to batching. Any unknown dimensions will be padded to the maximum size\n",
      " |          of that dimension in each batch. If unset, all dimensions of all\n",
      " |          components are padded to the maximum size in the batch. `padded_shapes`\n",
      " |          must be set if any component has an unknown rank.\n",
      " |        padding_values: (Optional.) A nested structure of scalar-shaped\n",
      " |          `tf.Tensor`, representing the padding values to use for the respective\n",
      " |          components. None represents that the nested structure should be padded\n",
      " |          with default values.  Defaults are `0` for numeric types and the empty\n",
      " |          string for string types. The `padding_values` should have the\n",
      " |          same structure as the input dataset. If `padding_values` is a single\n",
      " |          element and the input dataset has multiple components, then the same\n",
      " |          `padding_values` will be used to pad every component of the dataset.\n",
      " |          If `padding_values` is a scalar, then its value will be broadcasted\n",
      " |          to match the shape of each component.\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If a component has an unknown rank, and  the `padded_shapes`\n",
      " |          argument is not set.\n",
      " |  \n",
      " |  prefetch(self, buffer_size)\n",
      " |      Creates a `Dataset` that prefetches elements from this dataset.\n",
      " |      \n",
      " |      Most dataset input pipelines should end with a call to `prefetch`. This\n",
      " |      allows later elements to be prepared while the current element is being\n",
      " |      processed. This often improves latency and throughput, at the cost of\n",
      " |      using additional memory to store prefetched elements.\n",
      " |      \n",
      " |      Note: Like other `Dataset` methods, prefetch operates on the\n",
      " |      elements of the input dataset. It has no concept of examples vs. batches.\n",
      " |      `examples.prefetch(2)` will prefetch two elements (2 examples),\n",
      " |      while `examples.batch(20).prefetch(2)` will prefetch 2 elements\n",
      " |      (2 batches, of 20 examples each).\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> dataset = dataset.prefetch(2)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2]\n",
      " |      \n",
      " |      Args:\n",
      " |        buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the maximum\n",
      " |          number of elements that will be buffered when prefetching.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  reduce(self, initial_state, reduce_func)\n",
      " |      Reduces the input dataset to a single element.\n",
      " |      \n",
      " |      The transformation calls `reduce_func` successively on every element of\n",
      " |      the input dataset until the dataset is exhausted, aggregating information in\n",
      " |      its internal state. The `initial_state` argument is used for the initial\n",
      " |      state and the final state is returned as the result.\n",
      " |      \n",
      " |      >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
      " |      5\n",
      " |      >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()\n",
      " |      10\n",
      " |      \n",
      " |      Args:\n",
      " |        initial_state: An element representing the initial state of the\n",
      " |          transformation.\n",
      " |        reduce_func: A function that maps `(old_state, input_element)` to\n",
      " |          `new_state`. It must take two arguments and return a new element\n",
      " |          The structure of `new_state` must match the structure of\n",
      " |          `initial_state`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dataset element corresponding to the final state of the transformation.\n",
      " |  \n",
      " |  repeat(self, count=None)\n",
      " |      Repeats this dataset so each original value is seen `count` times.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.repeat(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
      " |      \n",
      " |      Note: If this dataset is a function of global state (e.g. a random number\n",
      " |      generator), then different repetitions may produce different elements.\n",
      " |      \n",
      " |      Args:\n",
      " |        count: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          number of times the dataset should be repeated. The default behavior (if\n",
      " |          `count` is `None` or `-1`) is for the dataset be repeated indefinitely.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  shard(self, num_shards, index)\n",
      " |      Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
      " |      \n",
      " |      `shard` is deterministic. The Dataset produced by `A.shard(n, i)` will\n",
      " |      contain all elements of A whose index mod n = i.\n",
      " |      \n",
      " |      >>> A = tf.data.Dataset.range(10)\n",
      " |      >>> B = A.shard(num_shards=3, index=0)\n",
      " |      >>> list(B.as_numpy_iterator())\n",
      " |      [0, 3, 6, 9]\n",
      " |      >>> C = A.shard(num_shards=3, index=1)\n",
      " |      >>> list(C.as_numpy_iterator())\n",
      " |      [1, 4, 7]\n",
      " |      >>> D = A.shard(num_shards=3, index=2)\n",
      " |      >>> list(D.as_numpy_iterator())\n",
      " |      [2, 5, 8]\n",
      " |      \n",
      " |      This dataset operator is very useful when running distributed training, as\n",
      " |      it allows each worker to read a unique subset.\n",
      " |      \n",
      " |      When reading a single input file, you can shard elements as follows:\n",
      " |      \n",
      " |      ```python\n",
      " |      d = tf.data.TFRecordDataset(input_file)\n",
      " |      d = d.shard(num_workers, worker_index)\n",
      " |      d = d.repeat(num_epochs)\n",
      " |      d = d.shuffle(shuffle_buffer_size)\n",
      " |      d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
      " |      ```\n",
      " |      \n",
      " |      Important caveats:\n",
      " |      \n",
      " |      - Be sure to shard before you use any randomizing operator (such as\n",
      " |        shuffle).\n",
      " |      - Generally it is best if the shard operator is used early in the dataset\n",
      " |        pipeline. For example, when reading from a set of TFRecord files, shard\n",
      " |        before converting the dataset to input samples. This avoids reading every\n",
      " |        file on every worker. The following is an example of an efficient\n",
      " |        sharding strategy within a complete pipeline:\n",
      " |      \n",
      " |      ```python\n",
      " |      d = Dataset.list_files(pattern)\n",
      " |      d = d.shard(num_workers, worker_index)\n",
      " |      d = d.repeat(num_epochs)\n",
      " |      d = d.shuffle(shuffle_buffer_size)\n",
      " |      d = d.interleave(tf.data.TFRecordDataset,\n",
      " |                       cycle_length=num_readers, block_length=1)\n",
      " |      d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        num_shards: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          shards operating in parallel.\n",
      " |        index: A `tf.int64` scalar `tf.Tensor`, representing the worker index.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        InvalidArgumentError: if `num_shards` or `index` are illegal values.\n",
      " |      \n",
      " |          Note: error checking is done on a best-effort basis, and errors aren't\n",
      " |          guaranteed to be caught upon dataset creation. (e.g. providing in a\n",
      " |          placeholder tensor bypasses the early checking, and will instead result\n",
      " |          in an error during a session.run call.)\n",
      " |  \n",
      " |  shuffle(self, buffer_size, seed=None, reshuffle_each_iteration=None)\n",
      " |      Randomly shuffles the elements of this dataset.\n",
      " |      \n",
      " |      This dataset fills a buffer with `buffer_size` elements, then randomly\n",
      " |      samples elements from this buffer, replacing the selected elements with new\n",
      " |      elements. For perfect shuffling, a buffer size greater than or equal to the\n",
      " |      full size of the dataset is required.\n",
      " |      \n",
      " |      For instance, if your dataset contains 10,000 elements but `buffer_size` is\n",
      " |      set to 1,000, then `shuffle` will initially select a random element from\n",
      " |      only the first 1,000 elements in the buffer. Once an element is selected,\n",
      " |      its space in the buffer is replaced by the next (i.e. 1,001-st) element,\n",
      " |      maintaining the 1,000 element buffer.\n",
      " |      \n",
      " |      `reshuffle_each_iteration` controls whether the shuffle order should be\n",
      " |      different for each epoch. In TF 1.X, the idiomatic way to create epochs\n",
      " |      was through the `repeat` transformation:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
      " |      >>> dataset = dataset.repeat(2)  # doctest: +SKIP\n",
      " |      [1, 0, 2, 1, 2, 0]\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
      " |      >>> dataset = dataset.repeat(2)  # doctest: +SKIP\n",
      " |      [1, 0, 2, 1, 0, 2]\n",
      " |      \n",
      " |      In TF 2.0, `tf.data.Dataset` objects are Python iterables which makes it\n",
      " |      possible to also create epochs through Python iteration:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
      " |      >>> list(dataset.as_numpy_iterator())  # doctest: +SKIP\n",
      " |      [1, 0, 2]\n",
      " |      >>> list(dataset.as_numpy_iterator())  # doctest: +SKIP\n",
      " |      [1, 2, 0]\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
      " |      >>> list(dataset.as_numpy_iterator())  # doctest: +SKIP\n",
      " |      [1, 0, 2]\n",
      " |      >>> list(dataset.as_numpy_iterator())  # doctest: +SKIP\n",
      " |      [1, 0, 2]\n",
      " |      \n",
      " |      Args:\n",
      " |        buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements from this dataset from which the new dataset will sample.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |        reshuffle_each_iteration: (Optional.) A boolean, which if true indicates\n",
      " |          that the dataset should be pseudorandomly reshuffled each time it is\n",
      " |          iterated over. (Defaults to `True`.)\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  skip(self, count)\n",
      " |      Creates a `Dataset` that skips `count` elements from this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.skip(7)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [7, 8, 9]\n",
      " |      \n",
      " |      Args:\n",
      " |        count: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements of this dataset that should be skipped to form the new dataset.\n",
      " |          If `count` is greater than the size of this dataset, the new dataset\n",
      " |          will contain no elements.  If `count` is -1, skips the entire dataset.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  take(self, count)\n",
      " |      Creates a `Dataset` with at most `count` elements from this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.take(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2]\n",
      " |      \n",
      " |      Args:\n",
      " |        count: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements of this dataset that should be taken to form the new dataset.\n",
      " |          If `count` is -1, or if `count` is greater than the size of this\n",
      " |          dataset, the new dataset will contain all elements of this dataset.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  unbatch(self)\n",
      " |      Splits elements of a dataset into multiple elements.\n",
      " |      \n",
      " |      For example, if elements of the dataset are shaped `[B, a0, a1, ...]`,\n",
      " |      where `B` may vary for each input element, then for each element in the\n",
      " |      dataset, the unbatched dataset will contain `B` consecutive elements\n",
      " |      of shape `[a0, a1, ...]`.\n",
      " |      \n",
      " |      >>> elements = [ [1, 2, 3], [1, 2], [1, 2, 3, 4] ]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64)\n",
      " |      >>> dataset = dataset.unbatch()\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 1, 2, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Note: `unbatch` requires a data copy to slice up the batched tensor into\n",
      " |      smaller, unbatched tensors. When optimizing performance, try to avoid\n",
      " |      unnecessary usage of `unbatch`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  window(self, size, shift=None, stride=1, drop_remainder=False)\n",
      " |      Combines (nests of) input elements into a dataset of (nests of) windows.\n",
      " |      \n",
      " |      A \"window\" is a finite dataset of flat elements of size `size` (or possibly\n",
      " |      fewer if there are not enough input elements to fill the window and\n",
      " |      `drop_remainder` evaluates to `False`).\n",
      " |      \n",
      " |      The `shift` argument determines the number of input elements by which the\n",
      " |      window moves on each iteration.  If windows and elements are both numbered\n",
      " |      starting at 0, the first element in window `k` will be element `k * shift`\n",
      " |      of the input dataset. In particular, the first element of the first window\n",
      " |      will always be the first element of the input dataset.\n",
      " |      \n",
      " |      The `stride` argument determines the stride of the input elements, and the\n",
      " |      `shift` argument determines the shift of the window.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(2)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(list(window.as_numpy_iterator()))\n",
      " |      [0, 1]\n",
      " |      [2, 3]\n",
      " |      [4, 5]\n",
      " |      [6]\n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3, 2, 1, True)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(list(window.as_numpy_iterator()))\n",
      " |      [0, 1, 2]\n",
      " |      [2, 3, 4]\n",
      " |      [4, 5, 6]\n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3, 1, 2, True)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(list(window.as_numpy_iterator()))\n",
      " |      [0, 2, 4]\n",
      " |      [1, 3, 5]\n",
      " |      [2, 4, 6]\n",
      " |      \n",
      " |      Note that when the `window` transformation is applied to a dataset of\n",
      " |      nested elements, it produces a dataset of nested windows.\n",
      " |      \n",
      " |      >>> nested = ([1, 2, 3, 4], [5, 6, 7, 8])\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(nested).window(2)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   def to_numpy(ds):\n",
      " |      ...     return list(ds.as_numpy_iterator())\n",
      " |      ...   print(tuple(to_numpy(component) for component in window))\n",
      " |      ([1, 2], [5, 6])\n",
      " |      ([3, 4], [7, 8])\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({'a': [1, 2, 3, 4]})\n",
      " |      >>> dataset = dataset.window(2)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   def to_numpy(ds):\n",
      " |      ...     return list(ds.as_numpy_iterator())\n",
      " |      ...   print({'a': to_numpy(window['a'])})\n",
      " |      {'a': [1, 2]}\n",
      " |      {'a': [3, 4]}\n",
      " |      \n",
      " |      Args:\n",
      " |        size: A `tf.int64` scalar `tf.Tensor`, representing the number of elements\n",
      " |          of the input dataset to combine into a window. Must be positive.\n",
      " |        shift: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          number of input elements by which the window moves in each iteration.\n",
      " |          Defaults to `size`. Must be positive.\n",
      " |        stride: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          stride of the input elements in the sliding window. Must be positive.\n",
      " |          The default value of 1 means \"retain every input element\".\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last windows should be dropped if their size is smaller than\n",
      " |          `size`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset` of (nests of) windows -- a finite datasets of flat\n",
      " |          elements created from the (nests of) input elements.\n",
      " |  \n",
      " |  with_options(self, options)\n",
      " |      Returns a new `tf.data.Dataset` with the given options set.\n",
      " |      \n",
      " |      The options are \"global\" in the sense they apply to the entire dataset.\n",
      " |      If options are set multiple times, they are merged as long as different\n",
      " |      options do not use different non-default values.\n",
      " |      \n",
      " |      >>> ds = tf.data.Dataset.range(5)\n",
      " |      >>> ds = ds.interleave(lambda x: tf.data.Dataset.range(5),\n",
      " |      ...                    cycle_length=3,\n",
      " |      ...                    num_parallel_calls=3)\n",
      " |      >>> options = tf.data.Options()\n",
      " |      >>> # This will make the interleave order non-deterministic.\n",
      " |      >>> options.experimental_deterministic = False\n",
      " |      >>> ds = ds.with_options(options)\n",
      " |      \n",
      " |      Args:\n",
      " |        options: A `tf.data.Options` that identifies the options the use.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset` with the given options.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: when an option is set more than once to a non-default value\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from DatasetV2:\n",
      " |  \n",
      " |  from_generator(generator, output_types=None, output_shapes=None, args=None, output_signature=None)\n",
      " |      Creates a `Dataset` whose elements are generated by `generator`. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(output_shapes, output_types)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Use output_signature instead\n",
      " |      \n",
      " |      The `generator` argument must be a callable object that returns\n",
      " |      an object that supports the `iter()` protocol (e.g. a generator function).\n",
      " |      \n",
      " |      The elements generated by `generator` must be compatible with either the\n",
      " |      given `output_signature` argument or with the given `output_types` and\n",
      " |      (optionally) `output_shapes` arguments, whichiver was specified.\n",
      " |      \n",
      " |      The recommended way to call `from_generator` is to use the\n",
      " |      `output_signature` argument. In this case the output will be assumed to\n",
      " |      consist of objects with the classes, shapes and types defined by\n",
      " |      `tf.TypeSpec` objects from `output_signature` argument:\n",
      " |      \n",
      " |      >>> def gen():\n",
      " |      ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])\n",
      " |      ...   yield 42, ragged_tensor\n",
      " |      >>>\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...      gen,\n",
      " |      ...      output_signature=(\n",
      " |      ...          tf.TensorSpec(shape=(), dtype=tf.int32),\n",
      " |      ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))\n",
      " |      >>>\n",
      " |      >>> list(dataset.take(1))\n",
      " |      [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,\n",
      " |      <tf.RaggedTensor [[1, 2], [3]]>)]\n",
      " |      \n",
      " |      There is also a deprecated way to call `from_generator` by either with\n",
      " |      `output_types` argument alone or together with `output_shapes` argument.\n",
      " |      In this case the output of the function will be assumed to consist of\n",
      " |      `tf.Tensor` objects with with the types defined by `output_types` and with\n",
      " |      the shapes which are either unknown or defined by `output_shapes`.\n",
      " |      \n",
      " |      Note: The current implementation of `Dataset.from_generator()` uses\n",
      " |      `tf.numpy_function` and inherits the same constraints. In particular, it\n",
      " |      requires the dataset and iterator related operations to be placed\n",
      " |      on a device in the same process as the Python program that called\n",
      " |      `Dataset.from_generator()`. The body of `generator` will not be\n",
      " |      serialized in a `GraphDef`, and you should not use this method if you\n",
      " |      need to serialize your model and restore it in a different environment.\n",
      " |      \n",
      " |      Note: If `generator` depends on mutable global variables or other external\n",
      " |      state, be aware that the runtime may invoke `generator` multiple times\n",
      " |      (in order to support repeating the `Dataset`) and at any time\n",
      " |      between the call to `Dataset.from_generator()` and the production of the\n",
      " |      first element from the generator. Mutating global variables or external\n",
      " |      state can cause undefined behavior, and we recommend that you explicitly\n",
      " |      cache any external state in `generator` before calling\n",
      " |      `Dataset.from_generator()`.\n",
      " |      \n",
      " |      Args:\n",
      " |        generator: A callable object that returns an object that supports the\n",
      " |          `iter()` protocol. If `args` is not specified, `generator` must take no\n",
      " |          arguments; otherwise it must take as many arguments as there are values\n",
      " |          in `args`.\n",
      " |        output_types: (Optional.) A nested structure of `tf.DType` objects\n",
      " |          corresponding to each component of an element yielded by `generator`.\n",
      " |        output_shapes: (Optional.) A nested structure of `tf.TensorShape` objects\n",
      " |          corresponding to each component of an element yielded by `generator`.\n",
      " |        args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated\n",
      " |          and passed to `generator` as NumPy-array arguments.\n",
      " |        output_signature: (Optional.) A nested structure of `tf.TypeSpec` objects\n",
      " |          corresponding to each component of an element yielded by `generator`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  from_tensor_slices(tensors)\n",
      " |      Creates a `Dataset` whose elements are slices of the given tensors.\n",
      " |      \n",
      " |      The given tensors are sliced along their first dimension. This operation\n",
      " |      preserves the structure of the input tensors, removing the first dimension\n",
      " |      of each tensor and using it as the dataset dimension. All input tensors\n",
      " |      must have the same size in their first dimensions.\n",
      " |      \n",
      " |      >>> # Slicing a 1D tensor produces scalar tensor elements.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      >>> # Slicing a 2D tensor produces 1D tensor elements.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\n",
      " |      \n",
      " |      >>> # Slicing a tuple of 1D tensors produces tuple elements containing\n",
      " |      >>> # scalar tensors.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(1, 3, 5), (2, 4, 6)]\n",
      " |      \n",
      " |      >>> # Dictionary structure is also preserved.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
      " |      >>> list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3},\n",
      " |      ...                                       {'a': 2, 'b': 4}]\n",
      " |      True\n",
      " |      \n",
      " |      >>> # Two tensors can be combined into one Dataset object.\n",
      " |      >>> features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
      " |      >>> labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
      " |      >>> dataset = Dataset.from_tensor_slices((features, labels))\n",
      " |      >>> # Both the features and the labels tensors can be converted\n",
      " |      >>> # to a Dataset object separately and combined after.\n",
      " |      >>> features_dataset = Dataset.from_tensor_slices(features)\n",
      " |      >>> labels_dataset = Dataset.from_tensor_slices(labels)\n",
      " |      >>> dataset = Dataset.zip((features_dataset, labels_dataset))\n",
      " |      >>> # A batched feature and label set can be converted to a Dataset\n",
      " |      >>> # in similar fashion.\n",
      " |      >>> batched_features = tf.constant([[[1, 3], [2, 3]],\n",
      " |      ...                                 [[2, 1], [1, 2]],\n",
      " |      ...                                 [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
      " |      >>> batched_labels = tf.constant([['A', 'A'],\n",
      " |      ...                               ['B', 'B'],\n",
      " |      ...                               ['A', 'B']], shape=(3, 2, 1))\n",
      " |      >>> dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (array([[1, 3],\n",
      " |             [2, 3]], dtype=int32), array([[b'A'],\n",
      " |             [b'A']], dtype=object))\n",
      " |      (array([[2, 1],\n",
      " |             [1, 2]], dtype=int32), array([[b'B'],\n",
      " |             [b'B']], dtype=object))\n",
      " |      (array([[3, 3],\n",
      " |             [3, 2]], dtype=int32), array([[b'A'],\n",
      " |             [b'B']], dtype=object))\n",
      " |      \n",
      " |      Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      " |      enabled, the values will be embedded in the graph as one or more\n",
      " |      `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      " |      memory and run into byte limits of graph serialization. If `tensors`\n",
      " |      contains one or more large NumPy arrays, consider the alternative described\n",
      " |      in [this guide](\n",
      " |      https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      " |      \n",
      " |      Args:\n",
      " |        tensors: A dataset element, with each component having the same size in\n",
      " |          the first dimension.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  from_tensors(tensors)\n",
      " |      Creates a `Dataset` with a single element, comprising the given tensors.\n",
      " |      \n",
      " |      `from_tensors` produces a dataset containing only a single element. To slice\n",
      " |      the input tensor into multiple elements, use `from_tensor_slices` instead.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2, 3], dtype=int32)]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A'))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(array([1, 2, 3], dtype=int32), b'A')]\n",
      " |      \n",
      " |      >>> # You can use `from_tensors` to produce a dataset which repeats\n",
      " |      >>> # the same example many times.\n",
      " |      >>> example = tf.constant([1,2,3])\n",
      " |      >>> dataset = tf.data.Dataset.from_tensors(example).repeat(2)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2, 3], dtype=int32), array([1, 2, 3], dtype=int32)]\n",
      " |      \n",
      " |      Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      " |      enabled, the values will be embedded in the graph as one or more\n",
      " |      `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      " |      memory and run into byte limits of graph serialization. If `tensors`\n",
      " |      contains one or more large NumPy arrays, consider the alternative described\n",
      " |      in [this\n",
      " |      guide](https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      " |      \n",
      " |      Args:\n",
      " |        tensors: A dataset element.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  list_files(file_pattern, shuffle=None, seed=None)\n",
      " |      A dataset of all files matching one or more glob patterns.\n",
      " |      \n",
      " |      The `file_pattern` argument should be a small number of glob patterns.\n",
      " |      If your filenames have already been globbed, use\n",
      " |      `Dataset.from_tensor_slices(filenames)` instead, as re-globbing every\n",
      " |      filename with `list_files` may result in poor performance with remote\n",
      " |      storage systems.\n",
      " |      \n",
      " |      Note: The default behavior of this method is to return filenames in\n",
      " |      a non-deterministic random shuffled order. Pass a `seed` or `shuffle=False`\n",
      " |      to get results in a deterministic order.\n",
      " |      \n",
      " |      Example:\n",
      " |        If we had the following files on our filesystem:\n",
      " |      \n",
      " |          - /path/to/dir/a.txt\n",
      " |          - /path/to/dir/b.py\n",
      " |          - /path/to/dir/c.py\n",
      " |      \n",
      " |        If we pass \"/path/to/dir/*.py\" as the directory, the dataset\n",
      " |        would produce:\n",
      " |      \n",
      " |          - /path/to/dir/b.py\n",
      " |          - /path/to/dir/c.py\n",
      " |      \n",
      " |      Args:\n",
      " |        file_pattern: A string, a list of strings, or a `tf.Tensor` of string type\n",
      " |          (scalar or vector), representing the filename glob (i.e. shell wildcard)\n",
      " |          pattern(s) that will be matched.\n",
      " |        shuffle: (Optional.) If `True`, the file names will be shuffled randomly.\n",
      " |          Defaults to `True`.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |      \n",
      " |      Returns:\n",
      " |       Dataset: A `Dataset` of strings corresponding to file names.\n",
      " |  \n",
      " |  range(*args, **kwargs)\n",
      " |      Creates a `Dataset` of a step-separated range of values.\n",
      " |      \n",
      " |      >>> list(Dataset.range(5).as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      >>> list(Dataset.range(2, 5).as_numpy_iterator())\n",
      " |      [2, 3, 4]\n",
      " |      >>> list(Dataset.range(1, 5, 2).as_numpy_iterator())\n",
      " |      [1, 3]\n",
      " |      >>> list(Dataset.range(1, 5, -2).as_numpy_iterator())\n",
      " |      []\n",
      " |      >>> list(Dataset.range(5, 1).as_numpy_iterator())\n",
      " |      []\n",
      " |      >>> list(Dataset.range(5, 1, -2).as_numpy_iterator())\n",
      " |      [5, 3]\n",
      " |      >>> list(Dataset.range(2, 5, output_type=tf.int32).as_numpy_iterator())\n",
      " |      [2, 3, 4]\n",
      " |      >>> list(Dataset.range(1, 5, 2, output_type=tf.float32).as_numpy_iterator())\n",
      " |      [1.0, 3.0]\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: follows the same semantics as python's xrange.\n",
      " |          len(args) == 1 -> start = 0, stop = args[0], step = 1.\n",
      " |          len(args) == 2 -> start = args[0], stop = args[1], step = 1.\n",
      " |          len(args) == 3 -> start = args[0], stop = args[1], step = args[2].\n",
      " |        **kwargs:\n",
      " |          - output_type: Its expected dtype. (Optional, default: `tf.int64`).\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `RangeDataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if len(args) == 0.\n",
      " |  \n",
      " |  zip(datasets)\n",
      " |      Creates a `Dataset` by zipping together the given datasets.\n",
      " |      \n",
      " |      This method has similar semantics to the built-in `zip()` function\n",
      " |      in Python, with the main difference being that the `datasets`\n",
      " |      argument can be an arbitrary nested structure of `Dataset` objects.\n",
      " |      \n",
      " |      >>> # The nested structure of the `datasets` argument determines the\n",
      " |      >>> # structure of elements in the resulting dataset.\n",
      " |      >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
      " |      >>> b = tf.data.Dataset.range(4, 7)  # ==> [ 4, 5, 6 ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, b))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(1, 4), (2, 5), (3, 6)]\n",
      " |      >>> ds = tf.data.Dataset.zip((b, a))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(4, 1), (5, 2), (6, 3)]\n",
      " |      >>>\n",
      " |      >>> # The `datasets` argument may contain an arbitrary number of datasets.\n",
      " |      >>> c = tf.data.Dataset.range(7, 13).batch(2)  # ==> [ [7, 8],\n",
      " |      ...                                            #       [9, 10],\n",
      " |      ...                                            #       [11, 12] ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, b, c))\n",
      " |      >>> for element in ds.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (1, 4, array([7, 8]))\n",
      " |      (2, 5, array([ 9, 10]))\n",
      " |      (3, 6, array([11, 12]))\n",
      " |      >>>\n",
      " |      >>> # The number of elements in the resulting dataset is the same as\n",
      " |      >>> # the size of the smallest dataset in `datasets`.\n",
      " |      >>> d = tf.data.Dataset.range(13, 15)  # ==> [ 13, 14 ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, d))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(1, 13), (2, 14)]\n",
      " |      \n",
      " |      Args:\n",
      " |        datasets: A nested structure of datasets.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from DatasetV2:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from collections.abc.Iterable:\n",
      " |  \n",
      " |  __subclasshook__(C) from abc.ABCMeta\n",
      " |      Abstract classes can override this to customize issubclass().\n",
      " |      \n",
      " |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      " |      It should return True, False or NotImplemented.  If it returns\n",
      " |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      " |      overrides the normal algorithm (and the outcome is cached).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gen.training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ad2138c2ae91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# import tensorflow_datasets as tfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from albumentations import (\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mCompose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomBrightness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJpegCompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHueSaturationValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomContrast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHorizontalFlip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mRotate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow_datasets as tfds\n",
    "from functools import partial\n",
    "from albumentations import (\n",
    "    Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast, HorizontalFlip,\n",
    "    Rotate\n",
    ")\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 18)\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "# TODO test on entire test dataset\n",
    "obj = s3.Object('canopy-production-ml', \"chips/cloudfree-merge-polygons/split/test/100/100_1000_1000.tif\")\n",
    "obj_bytes = io.BytesIO(obj.get()['Body'].read())\n",
    "with rasterio.open(obj_bytes) as src:\n",
    "    img_test = np.transpose(src.read(), (1, 2, 0))\n",
    "print(img_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = tf.image.convert_image_dtype(img_test,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = tf.image.random_flip_left_right(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package tensorflow._api.v2.image in tensorflow._api.v2:\n",
      "\n",
      "NAME\n",
      "    tensorflow._api.v2.image - Image ops.\n",
      "\n",
      "DESCRIPTION\n",
      "    The `tf.image` module contains various functions for image\n",
      "    processing and decoding-encoding Ops.\n",
      "    \n",
      "    Many of the encoding/decoding functions are also available in the\n",
      "    core `tf.io` module.\n",
      "    \n",
      "    ## Image processing\n",
      "    \n",
      "    ### Resizing\n",
      "    \n",
      "    The resizing Ops accept input images as tensors of several types. They always\n",
      "    output resized images as float32 tensors.\n",
      "    \n",
      "    The convenience function `tf.image.resize` supports both 4-D\n",
      "    and 3-D tensors as input and output.  4-D tensors are for batches of images,\n",
      "    3-D tensors for individual images.\n",
      "    \n",
      "    Resized images will be distorted if their original aspect ratio is not the\n",
      "    same as size. To avoid distortions see tf.image.resize_with_pad.\n",
      "    \n",
      "    *   `tf.image.resize`\n",
      "    *   `tf.image.resize_with_pad`\n",
      "    *   `tf.image.resize_with_crop_or_pad`\n",
      "    \n",
      "    The Class `tf.image.ResizeMethod` provides various resize methods like\n",
      "    `bilinear`, `nearest_neighbor`.\n",
      "    \n",
      "    ### Converting Between Colorspaces\n",
      "    \n",
      "    Image ops work either on individual images or on batches of images, depending on\n",
      "    the shape of their input Tensor.\n",
      "    \n",
      "    If 3-D, the shape is `[height, width, channels]`, and the Tensor represents one\n",
      "    image. If 4-D, the shape is `[batch_size, height, width, channels]`, and the\n",
      "    Tensor represents `batch_size` images.\n",
      "    \n",
      "    Currently, `channels` can usefully be 1, 2, 3, or 4. Single-channel images are\n",
      "    grayscale, images with 3 channels are encoded as either RGB or HSV. Images\n",
      "    with 2 or 4 channels include an alpha channel, which has to be stripped from the\n",
      "    image before passing the image to most image processing functions (and can be\n",
      "    re-attached later).\n",
      "    \n",
      "    Internally, images are either stored in as one `float32` per channel per pixel\n",
      "    (implicitly, values are assumed to lie in `[0,1)`) or one `uint8` per channel\n",
      "    per pixel (values are assumed to lie in `[0,255]`).\n",
      "    \n",
      "    TensorFlow can convert between images in RGB or HSV or YIQ.\n",
      "    \n",
      "    *   `tf.image.rgb_to_grayscale`, `tf.image.grayscale_to_rgb`\n",
      "    *   `tf.image.rgb_to_hsv`, `tf.image.hsv_to_rgb`\n",
      "    *   `tf.image.rgb_to_yiq`, `tf.image.yiq_to_rgb`\n",
      "    *   `tf.image.rgb_to_yuv`, `tf.image.yuv_to_rgb`\n",
      "    *   `tf.image.image_gradients`\n",
      "    *   `tf.image.convert_image_dtype`\n",
      "    \n",
      "    ### Image Adjustments\n",
      "    \n",
      "    TensorFlow provides functions to adjust images in various ways: brightness,\n",
      "    contrast, hue, and saturation.  Each adjustment can be done with predefined\n",
      "    parameters or with random parameters picked from predefined intervals. Random\n",
      "    adjustments are often useful to expand a training set and reduce overfitting.\n",
      "    \n",
      "    If several adjustments are chained it is advisable to minimize the number of\n",
      "    redundant conversions by first converting the images to the most natural data\n",
      "    type and representation.\n",
      "    \n",
      "    *   `tf.image.adjust_brightness`\n",
      "    *   `tf.image.adjust_contrast`\n",
      "    *   `tf.image.adjust_gamma`\n",
      "    *   `tf.image.adjust_hue`\n",
      "    *   `tf.image.adjust_jpeg_quality`\n",
      "    *   `tf.image.adjust_saturation`\n",
      "    *   `tf.image.random_brightness`\n",
      "    *   `tf.image.random_contrast`\n",
      "    *   `tf.image.random_hue`\n",
      "    *   `tf.image.random_saturation`\n",
      "    *   `tf.image.per_image_standardization`\n",
      "    \n",
      "    ### Working with Bounding Boxes\n",
      "    \n",
      "    *   `tf.image.draw_bounding_boxes`\n",
      "    *   `tf.image.combined_non_max_suppression`\n",
      "    *   `tf.image.generate_bounding_box_proposals`\n",
      "    *   `tf.image.non_max_suppression`\n",
      "    *   `tf.image.non_max_suppression_overlaps`\n",
      "    *   `tf.image.non_max_suppression_padded`\n",
      "    *   `tf.image.non_max_suppression_with_scores`\n",
      "    *   `tf.image.pad_to_bounding_box`\n",
      "    *   `tf.image.sample_distorted_bounding_box`\n",
      "    \n",
      "    ### Cropping\n",
      "    \n",
      "    *   `tf.image.central_crop`\n",
      "    *   `tf.image.crop_and_resize`\n",
      "    *   `tf.image.crop_to_bounding_box`\n",
      "    *   `tf.io.decode_and_crop_jpeg`\n",
      "    *   `tf.image.extract_glimpse`\n",
      "    *   `tf.image.random_crop`\n",
      "    *   `tf.image.resize_with_crop_or_pad`\n",
      "    \n",
      "    ### Flipping, Rotating and Transposing\n",
      "    \n",
      "    *   `tf.image.flip_left_right`\n",
      "    *   `tf.image.flip_up_down`\n",
      "    *   `tf.image.random_flip_left_right`\n",
      "    *   `tf.image.random_flip_up_down`\n",
      "    *   `tf.image.rot90`\n",
      "    *   `tf.image.transpose`\n",
      "    \n",
      "    ## Image decoding and encoding\n",
      "    \n",
      "    TensorFlow provides Ops to decode and encode JPEG and PNG formats.  Encoded\n",
      "    images are represented by scalar string Tensors, decoded images by 3-D uint8\n",
      "    tensors of shape `[height, width, channels]`. (PNG also supports uint16.)\n",
      "    \n",
      "    Note: `decode_gif` returns a 4-D array `[num_frames, height, width, 3]`\n",
      "    \n",
      "    The encode and decode Ops apply to one image at a time.  Their input and output\n",
      "    are all of variable size.  If you need fixed size images, pass the output of\n",
      "    the decode Ops to one of the cropping and resizing Ops.\n",
      "    \n",
      "    *   `tf.io.decode_bmp`\n",
      "    *   `tf.io.decode_gif`\n",
      "    *   `tf.io.decode_image`\n",
      "    *   `tf.io.decode_jpeg`\n",
      "    *   `tf.io.decode_and_crop_jpeg`\n",
      "    *   `tf.io.decode_png`\n",
      "    *   `tf.io.encode_jpeg`\n",
      "    *   `tf.io.encode_png`\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "\n",
      "\n",
      "FILE\n",
      "    /Users/purgatorid/opt/anaconda3/envs/ml-conda/lib/python3.7/site-packages/tensorflow/_api/v2/image/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## David's area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "\n",
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation enabled \n",
      "Training on 7886 images \n",
      "Validation on 366 images \n",
      "Your training file is missing positive labels for classes ['3']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "gen = DataLoader(label_file_path_train=\"labels_1_4_train_v2.csv\",\n",
    "                 label_file_path_val=\"val_labels.csv\",\n",
    "                 bucket_name='canopy-production-ml',\n",
    "                 data_extension_type='.tif',\n",
    "                 training_data_shape=(100, 100, 18),\n",
    "                 augment=True,\n",
    "                 random_flip_up_down=False, #Randomly flips an image vertically (upside down). With a 1 in 2 chance, outputs the contents of `image` flipped along the first dimension, which is `height`.\n",
    "                 random_flip_left_right=False,\n",
    "                 flip_left_right=True,\n",
    "                 flip_up_down=True,\n",
    "                 rot90=False,\n",
    "                 transpose=False,\n",
    "                 enable_shuffle=True,\n",
    "                 # training_data_shuffle_buffer_size=10,\n",
    "                 training_data_batch_size=batch_size,\n",
    "                 training_data_type=tf.float32,\n",
    "                 label_data_type=tf.uint8,\n",
    "                 enable_data_prefetch=True,\n",
    "                 data_prefetch_size=tf.data.experimental.AUTOTUNE,\n",
    "                 num_parallel_calls=int(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.7809829059829063,\n",
       " 1: 0.6314895681707908,\n",
       " 2: 1.1188480550182678,\n",
       " 4: 0.6000461041954819,\n",
       " 5: 1.9281481481481484,\n",
       " 6: 1.6574339382362304,\n",
       " 7: 1.2629791363415817,\n",
       " 8: 0.8022807828633072,\n",
       " 9: 0.7483110536150641}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(numclasses,input_shape):\n",
    "    # parameters for CNN\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # introduce a additional layer to get from bands to 3 input channels\n",
    "    input_tensor = Conv2D(3, (1, 1))(input_tensor)\n",
    "\n",
    "    base_model_resnet50 = keras.applications.ResNet50(include_top=False,\n",
    "                              weights='imagenet',\n",
    "                              input_shape=(100, 100, 3))\n",
    "    base_model = keras.applications.ResNet50(include_top=False,\n",
    "                     weights=None,\n",
    "                     input_tensor=input_tensor)\n",
    "\n",
    "    for i, layer in enumerate(base_model_resnet50.layers):\n",
    "        # we must skip input layer, which has no weights\n",
    "        if i == 0:\n",
    "            continue\n",
    "        base_model.layers[i+1].set_weights(layer.get_weights())\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    top_model = base_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "    # and a logistic layer\n",
    "    predictions = Dense(numclasses, activation='softmax')(top_model)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Currently logged in as: davidanagy (use `wandb login --relogin` to force relogin)\n",
      "C:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\IPython\\html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "wandb: wandb version 0.10.21 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/davidanagy/canopy-first-model-testing\" target=\"_blank\">https://wandb.ai/davidanagy/canopy-first-model-testing</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/davidanagy/canopy-first-model-testing/runs/2v4mxph8\" target=\"_blank\">https://wandb.ai/davidanagy/canopy-first-model-testing/runs/2v4mxph8</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\David\\canopy\\cb_feature_detection\\model-development\\wandb\\run-20210305_165733-2v4mxph8</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2v4mxph8)</h1><iframe src=\"https://wandb.ai/davidanagy/canopy-first-model-testing/runs/2v4mxph8\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x16daf393208>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\n",
    "wandb.init(project=\"canopy-first-model-testing\", name=\"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function init in module wandb.sdk.wandb_init:\n",
      "\n",
      "init(job_type: Union[str, NoneType] = None, dir=None, config: Union[Dict, str, NoneType] = None, project: Union[str, NoneType] = None, entity: Union[str, NoneType] = None, reinit: bool = None, tags: Union[Sequence, NoneType] = None, group: Union[str, NoneType] = None, name: Union[str, NoneType] = None, notes: Union[str, NoneType] = None, magic: Union[dict, str, bool] = None, config_exclude_keys=None, config_include_keys=None, anonymous: Union[str, NoneType] = None, mode: Union[str, NoneType] = None, allow_val_change: Union[bool, NoneType] = None, resume: Union[bool, str, NoneType] = None, force: Union[bool, NoneType] = None, tensorboard=None, sync_tensorboard=None, monitor_gym=None, save_code=None, id=None, settings: Union[wandb.sdk.wandb_settings.Settings, Dict[str, Any], NoneType] = None) -> Union[wandb.sdk.wandb_run.Run, wandb.sdk.lib.disabled.RunDisabled, NoneType]\n",
      "    Start a new tracked run with `wandb.init()`.\n",
      "    \n",
      "    In an ML training pipeline, you could add `wandb.init()`\n",
      "    to the beginning of your training script as well as your evaluation\n",
      "    script, and each piece would be tracked as a run in W&B.\n",
      "    \n",
      "    `wandb.init()` spawns a new background process to log data to a run, and it\n",
      "    also syncs data to wandb.ai by default so you can see live visualizations.\n",
      "    Call `wandb.init()` to start a run before logging data with `wandb.log()`.\n",
      "    \n",
      "    `wandb.init()` returns a run object, and you can also access the run object\n",
      "    with wandb.run.\n",
      "    \n",
      "    Arguments:\n",
      "        project: (str, optional) The name of the project where you're sending\n",
      "            the new run. If the project is not specified, the run is put in an\n",
      "            \"Uncategorized\" project.\n",
      "        entity: (str, optional) An entity is a username or team name where\n",
      "            you're sending runs. This entity must exist before you can send runs\n",
      "            there, so make sure to create your account or team in the UI before\n",
      "            starting to log runs.\n",
      "            If you don't specify an entity, the run will be sent to your default\n",
      "            entity, which is usually your username. Change your default entity\n",
      "            in [Settings](wandb.ai/settings) under \"default location to create\n",
      "            new projects\".\n",
      "        config: (dict, argparse, absl.flags, str, optional)\n",
      "            This sets wandb.config, a dictionary-like object for saving inputs\n",
      "            to your job, like hyperparameters for a model or settings for a data\n",
      "            preprocessing job. The config will show up in a table in the UI that\n",
      "            you can use to group, filter, and sort runs. Keys should not contain\n",
      "            `.` in their names, and values should be under 10 MB.\n",
      "            If dict, argparse or absl.flags: will load the key value pairs into\n",
      "                the wandb.config object.\n",
      "            If str: will look for a yaml file by that name, and load config from\n",
      "                that file into the wandb.config object.\n",
      "        save_code: (bool, optional) Turn this on to save the main script or\n",
      "            notebook to W&B. This is valuable for improving experiment\n",
      "            reproducibility and to diff code across experiments in the UI. By\n",
      "            default this is off, but you can flip the default behavior to \"on\"\n",
      "            in [Settings](wandb.ai/settings).\n",
      "        group: (str, optional) Specify a group to organize individual runs into\n",
      "            a larger experiment. For example, you might be doing cross\n",
      "            validation, or you might have multiple jobs that train and evaluate\n",
      "            a model against different test sets. Group gives you a way to\n",
      "            organize runs together into a larger whole, and you can toggle this\n",
      "            on and off in the UI. For more details, see\n",
      "            [Grouping](docs.wandb.com/library/grouping).\n",
      "        job_type: (str, optional) Specify the type of run, which is useful when\n",
      "            you're grouping runs together into larger experiments using group.\n",
      "            For example, you might have multiple jobs in a group, with job types\n",
      "            like train and eval. Setting this makes it easy to filter and group\n",
      "            similar runs together in the UI so you can compare apples to apples.\n",
      "        tags: (list, optional) A list of strings, which will populate the list\n",
      "            of tags on this run in the UI. Tags are useful for organizing runs\n",
      "            together, or applying temporary labels like \"baseline\" or\n",
      "            \"production\". It's easy to add and remove tags in the UI, or filter\n",
      "            down to just runs with a specific tag.\n",
      "        name: (str, optional) A short display name for this run, which is how\n",
      "            you'll identify this run in the UI. By default we generate a random\n",
      "            two-word name that lets you easily cross-reference runs from the\n",
      "            table to charts. Keeping these run names short makes the chart\n",
      "            legends and tables easier to read. If you're looking for a place to\n",
      "            save your hyperparameters, we recommend saving those in config.\n",
      "        notes: (str, optional) A longer description of the run, like a -m commit\n",
      "            message in git. This helps you remember what you were doing when you\n",
      "            ran this run.\n",
      "        dir: (str, optional) An absolute path to a directory where metadata will\n",
      "            be stored. When you call download() on an artifact, this is the\n",
      "            directory where downloaded files will be saved. By default this is\n",
      "            the ./wandb directory.\n",
      "        sync_tensorboard: (bool, optional) Whether to copy all TensorBoard logs\n",
      "            to W&B (default: False).\n",
      "            [Tensorboard](https://docs.wandb.com/integrations/tensorboard)\n",
      "        resume (bool, str, optional): Sets the resuming behavior. Options:\n",
      "            \"allow\", \"must\", \"never\", \"auto\" or None. Defaults to None.\n",
      "            Cases:\n",
      "            - None (default): If the new run has the same ID as a previous run,\n",
      "                this run overwrites that data.\n",
      "            - \"auto\" (or True): if the preivous run on this machine crashed,\n",
      "                automatically resume it. Otherwise, start a new run.\n",
      "            - \"allow\": if id is set with init(id=\"UNIQUE_ID\") or\n",
      "                WANDB_RUN_ID=\"UNIQUE_ID\" and it is identical to a previous run,\n",
      "                wandb will automatically resume the run with that id. Otherwise,\n",
      "                wandb will start a new run.\n",
      "            - \"never\": if id is set with init(id=\"UNIQUE_ID\") or\n",
      "                WANDB_RUN_ID=\"UNIQUE_ID\" and it is identical to a previous run,\n",
      "                wandb will crash.\n",
      "            - \"must\": if id is set with init(id=\"UNIQUE_ID\") or\n",
      "                WANDB_RUN_ID=\"UNIQUE_ID\" and it is identical to a previous run,\n",
      "                wandb will automatically resume the run with the id. Otherwise\n",
      "                wandb will crash.\n",
      "            See https://docs.wandb.com/library/advanced/resuming for more.\n",
      "        reinit: (bool, optional) Allow multiple wandb.init() calls in the same\n",
      "            process. (default: False)\n",
      "        magic: (bool, dict, or str, optional) The bool controls whether we try to\n",
      "            auto-instrument your script, capturing basic details of your run\n",
      "            without you having to add more wandb code. (default: False)\n",
      "            You can also pass a dict, json string, or yaml filename.\n",
      "        config_exclude_keys: (list, optional) string keys to exclude from\n",
      "            `wandb.config`.\n",
      "        config_include_keys: (list, optional) string keys to include in\n",
      "            wandb.config.\n",
      "        anonymous: (str, optional) Controls anonymous data logging. Options:\n",
      "            - \"never\" (default): requires you to link your W&B account before\n",
      "                tracking the run so you don't accidentally create an anonymous\n",
      "                run.\n",
      "            - \"allow\": lets a logged-in user track runs with their account, but\n",
      "                lets someone who is running the script without a W&B account see\n",
      "                the charts in the UI.\n",
      "            - \"must\": sends the run to an anonymous account instead of to a\n",
      "                signed-up user account.\n",
      "        mode: (str, optional) Can be \"online\", \"offline\" or \"disabled\". Defaults to\n",
      "            online.\n",
      "        allow_val_change: (bool, optional) Whether to allow config values to\n",
      "            change after setting the keys once. By default we throw an exception\n",
      "            if a config value is overwritten. If you want to track something\n",
      "            like a varying learning_rate at multiple times during training, use\n",
      "            wandb.log() instead. (default: False in scripts, True in Jupyter)\n",
      "        force: (bool, optional) If True, this crashes the script if a user isn't\n",
      "            logged in to W&B. If False, this will let the script run in offline\n",
      "            mode if a user isn't logged in to W&B. (default: False)\n",
      "        sync_tensorboard: (bool, optional) Synchronize wandb logs from tensorboard or\n",
      "            tensorboardX and saves the relevant events file. Defaults to false.\n",
      "        monitor_gym: (bool, optional) automatically logs videos of environment when\n",
      "            using OpenAI Gym. (default: False)\n",
      "            See https://docs.wandb.com/library/integrations/openai-gym\n",
      "        id: (str, optional) A unique ID for this run, used for Resuming. It must\n",
      "            be unique in the project, and if you delete a run you can't reuse\n",
      "            the ID. Use the name field for a short descriptive name, or config\n",
      "            for saving hyperparameters to compare across runs. The ID cannot\n",
      "            contain special characters.\n",
      "            See https://docs.wandb.com/library/resuming\n",
      "    \n",
      "    \n",
      "    Examples:\n",
      "        Basic usage\n",
      "        ```\n",
      "        wandb.init()\n",
      "        ```\n",
      "    \n",
      "        Launch multiple runs from the same script\n",
      "        ```\n",
      "        for x in range(10):\n",
      "            with wandb.init(project=\"my-projo\") as run:\n",
      "                for y in range(100):\n",
      "                    run.log({\"metric\": x+y})\n",
      "        ```\n",
      "    \n",
      "    Raises:\n",
      "        Exception: if problem.\n",
      "    \n",
      "    Returns:\n",
      "        A `Run` object.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(wandb.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class WandbCallback in module wandb.integration.keras.keras:\n",
      "\n",
      "class WandbCallback(tensorflow.python.keras.callbacks.Callback)\n",
      " |  WandbCallback(monitor='val_loss', verbose=0, mode='auto', save_weights_only=False, log_weights=False, log_gradients=False, save_model=True, training_data=None, validation_data=None, labels=[], data_type=None, predictions=36, generator=None, input_type=None, output_type=None, log_evaluation=False, validation_steps=None, class_colors=None, log_batch_frequency=None, log_best_prefix='best_', save_graph=True)\n",
      " |  \n",
      " |  WandbCallback automatically integrates keras with wandb.\n",
      " |  \n",
      " |  Example:\n",
      " |      ```\n",
      " |      model.fit(X_train, y_train,  validation_data=(X_test, y_test),\n",
      " |          callbacks=[WandbCallback()])\n",
      " |      ```\n",
      " |  \n",
      " |  WandbCallback will automatically log history data from any\n",
      " |      metrics collected by keras: loss and anything passed into keras_model.compile() \n",
      " |  \n",
      " |  WandbCallback will set summary metrics for the run associated with the \"best\" training\n",
      " |      step, where \"best\" is defined by the `monitor` and `mode` attribues.  This defaults\n",
      " |      to the epoch with the minimum val_loss. WandbCallback will by default save the model \n",
      " |      associated with the best epoch..\n",
      " |  \n",
      " |  WandbCallback can optionally log gradient and parameter histograms. \n",
      " |  \n",
      " |  WandbCallback can optionally save training and validation data for wandb to visualize.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      monitor (str): name of metric to monitor.  Defaults to val_loss.\n",
      " |      mode (str): one of {\"auto\", \"min\", \"max\"}.\n",
      " |          \"min\" - save model when monitor is minimized\n",
      " |          \"max\" - save model when monitor is maximized\n",
      " |          \"auto\" - try to guess when to save the model (default).\n",
      " |      save_model:\n",
      " |          True - save a model when monitor beats all previous epochs\n",
      " |          False - don't save models\n",
      " |      save_graph: (boolean): if True save model graph to wandb (default: True).\n",
      " |      save_weights_only (boolean): if True, then only the model's weights will be\n",
      " |          saved (`model.save_weights(filepath)`), else the full model\n",
      " |          is saved (`model.save(filepath)`).\n",
      " |      log_weights: (boolean) if True save histograms of the model's layer's weights.\n",
      " |      log_gradients: (boolean) if True log histograms of the training gradients\n",
      " |      training_data: (tuple) Same format (X,y) as passed to model.fit.  This is needed \n",
      " |          for calculating gradients - this is mandatory if `log_gradients` is `True`.\n",
      " |      validate_data: (tuple) Same format (X,y) as passed to model.fit.  A set of data \n",
      " |          for wandb to visualize.  If this is set, every epoch, wandb will\n",
      " |          make a small number of predictions and save the results for later visualization.\n",
      " |      generator (generator): a generator that returns validation data for wandb to visualize.  This\n",
      " |          generator should return tuples (X,y).  Either validate_data or generator should\n",
      " |          be set for wandb to visualize specific data examples.\n",
      " |      validation_steps (int): if `validation_data` is a generator, how many\n",
      " |          steps to run the generator for the full validation set.\n",
      " |      labels (list): If you are visualizing your data with wandb this list of labels \n",
      " |          will convert numeric output to understandable string if you are building a\n",
      " |          multiclass classifier.  If you are making a binary classifier you can pass in\n",
      " |          a list of two labels [\"label for false\", \"label for true\"].  If validate_data\n",
      " |          and generator are both false, this won't do anything.\n",
      " |      predictions (int): the number of predictions to make for visualization each epoch, max \n",
      " |          is 100.\n",
      " |      input_type (string): type of the model input to help visualization. can be one of:\n",
      " |          (\"image\", \"images\", \"segmentation_mask\").\n",
      " |      output_type (string): type of the model output to help visualziation. can be one of:\n",
      " |          (\"image\", \"images\", \"segmentation_mask\").  \n",
      " |      log_evaluation (boolean): if True save a dataframe containing the full\n",
      " |          validation results at the end of training.\n",
      " |      class_colors ([float, float, float]): if the input or output is a segmentation mask, \n",
      " |          an array containing an rgb tuple (range 0-1) for each class.\n",
      " |      log_batch_frequency (integer): if None, callback will log every epoch.\n",
      " |          If set to integer, callback will log training metrics every log_batch_frequency \n",
      " |          batches.\n",
      " |      log_best_prefix (string): if None, no extra summary metrics will be saved.\n",
      " |          If set to a string, the monitored metric and epoch will be prepended with this value\n",
      " |          and stored as summary metrics.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      WandbCallback\n",
      " |      tensorflow.python.keras.callbacks.Callback\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, monitor='val_loss', verbose=0, mode='auto', save_weights_only=False, log_weights=False, log_gradients=False, save_model=True, training_data=None, validation_data=None, labels=[], data_type=None, predictions=36, generator=None, input_type=None, output_type=None, log_evaluation=False, validation_steps=None, class_colors=None, log_batch_frequency=None, log_best_prefix='best_', save_graph=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  on_batch_begin(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_begin`.\n",
      " |  \n",
      " |  on_batch_end(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_end`.\n",
      " |  \n",
      " |  on_epoch_end(self, epoch, logs={})\n",
      " |      Called at the end of an epoch.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run. This function should only\n",
      " |      be called during TRAIN mode.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          epoch: Integer, index of epoch.\n",
      " |          logs: Dict, metric results for this training epoch, and for the\n",
      " |            validation epoch if validation is performed. Validation result keys\n",
      " |            are prefixed with `val_`.\n",
      " |  \n",
      " |  on_predict_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict, contains the return value of `model.predict_step`,\n",
      " |            it typically returns a dict with a key 'outputs' containing\n",
      " |            the model's outputs.\n",
      " |  \n",
      " |  on_predict_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_predict_begin(self, logs=None)\n",
      " |      Called at the beginning of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_end(self, logs=None)\n",
      " |      Called at the end of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the beginning of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict, contains the return value of `model.test_step`. Typically,\n",
      " |            the values of the `Model`'s metrics are returned.  Example:\n",
      " |            `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  on_test_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the end of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_test_begin(self, logs=None)\n",
      " |      Called at the beginning of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_end(self, logs=None)\n",
      " |      Called at the end of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: Dict. Currently the output of the last call to\n",
      " |            `on_test_batch_end()` is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict, contains the return value of `model.train_step`. Typically,\n",
      " |            the values of the `Model`'s metrics are returned.  Example:\n",
      " |            `{'loss': 0.2, 'accuracy': 0.7}`.\n",
      " |  \n",
      " |  on_train_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_train_begin(self, logs=None)\n",
      " |      Called at the beginning of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_end(self, logs=None)\n",
      " |      Called at the end of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: Dict. Currently the output of the last call to `on_epoch_end()`\n",
      " |            is passed to this argument for this method but that may change in\n",
      " |            the future.\n",
      " |  \n",
      " |  set_model(self, model)\n",
      " |  \n",
      " |  set_params(self, params)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.callbacks.Callback:\n",
      " |  \n",
      " |  on_epoch_begin(self, epoch, logs=None)\n",
      " |      Called at the start of an epoch.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run. This function should only\n",
      " |      be called during TRAIN mode.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          epoch: Integer, index of epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.callbacks.Callback:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WandbCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 18 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 100, 100, 3)  57          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 106, 106, 3)  0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 50, 50, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 50, 50, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 52, 52, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 25, 25, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 25, 25, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 25, 25, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 25, 25, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 25, 25, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 25, 25, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 25, 25, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 25, 25, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 25, 25, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 25, 25, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 25, 25, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 25, 25, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 25, 25, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 25, 25, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 25, 25, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 13, 13, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 13, 13, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 13, 13, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 13, 13, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 13, 13, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 13, 13, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 13, 13, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 13, 13, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 13, 13, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 13, 13, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 13, 13, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 13, 13, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 13, 13, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 13, 13, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 13, 13, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 13, 13, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 13, 13, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 13, 13, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 7, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 7, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 7, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 7, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 7, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 7, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 7, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 7, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 7, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 7, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 7, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 7, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 7, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 7, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 7, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 7, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 7, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 7, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 7, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 7, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 7, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 7, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         4196352     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         4196352     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20490       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 32,000,963\n",
      "Trainable params: 31,947,843\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random_id = 5555 #TODO\n",
    "checkpoint_file = 'checkpoint_{}.h5'.format(random_id)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "  filepath= checkpoint_file,\n",
    "  format='h5',\n",
    "  verbose=1,\n",
    "  save_weights_only=True,\n",
    "  monitor='val_loss',\n",
    "  mode='min',\n",
    "  save_best_only=True)\n",
    "\n",
    "reducelronplateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "  monitor='val_loss', factor=0.1, patience=10, verbose=1,\n",
    "  mode='min', min_lr=1e-10)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min', patience=20, verbose=1)\n",
    "\n",
    "#labels = [\"Habitation\", \"ISL\", \"Industrial_agriculture\", \"Mining\", \"Rainforest\",\n",
    "#          \"River\", \"Roads\", \"Savannah\", \"Shifting_cultivation\", \"Water\"] # Cut out mining b/c not in training data\n",
    "\n",
    "callbacks_list = [model_checkpoint_callback, reducelronplateau, early_stop]\n",
    "                  #WandbCallback(monitor='accuracy', data_type=\"image\", labels=labels)]\n",
    "\n",
    "model = define_model(10, (100,100,18))\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                          optimizer=keras.optimizers.Adam(),\n",
    "                          metrics=[tf.metrics.BinaryAccuracy(name='accuracy')]) #TODO add callbacks to save checkpoints and maybe lr reducer, earlystop,etc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.7809829059829063,\n",
       " 1: 0.6314895681707908,\n",
       " 2: 1.1188480550182678,\n",
       " 3: 1,\n",
       " 4: 0.6000461041954819,\n",
       " 5: 1.9281481481481484,\n",
       " 6: 1.6574339382362304,\n",
       " 7: 1.2629791363415817,\n",
       " 8: 0.8022807828633072,\n",
       " 9: 0.7483110536150641}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = gen.class_weight\n",
    "\n",
    "corrected_weights = {}\n",
    "\n",
    "for i in range(10):\n",
    "    if i == 3:\n",
    "        corrected_weights[i] = 1\n",
    "    else:\n",
    "        corrected_weights[i] = weights[i]\n",
    "        \n",
    "corrected_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ae583a577cb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                     class_weight=corrected_weights)\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m       \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \"\"\"\n\u001b[0;32m   1694\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   4043\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4044\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4045\u001b[1;33m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[0;32m   4046\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[0;32m   4047\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3369\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3370\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3371\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2937\u001b[0m     \"\"\"\n\u001b[0;32m   2938\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[1;32m-> 2939\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2941\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3362\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   3363\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3364\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3365\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3297\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3299\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3300\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3301\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\canopy_test_models\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_class_weights_map_fn\u001b[1;34m(*data)\u001b[0m\n\u001b[0;32m   1312\u001b[0m           \"`class_weight` is only supported for Models with a single output.\")\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m       raise ValueError(\"`class_weight` not supported for \"\n\u001b[0;32m   1316\u001b[0m                        \"3+ dimensional targets.\")\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(gen.training_dataset, validation_data=gen.validation_dataset, \n",
    "                    epochs=epochs, \n",
    "                    callbacks=callbacks_list,\n",
    "                    class_weight=corrected_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d0989e84fcd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrected_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'rank'"
     ]
    }
   ],
   "source": [
    "np.array(list(corrected_weights.values())).shape.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_models",
   "language": "python",
   "name": "canopy_test_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
