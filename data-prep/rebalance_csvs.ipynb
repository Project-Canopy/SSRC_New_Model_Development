{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code to rebalance CSV label files so that there's not a huge imbalance between labels. (In the raw data, the \"null\" labels far outnumber the labeled data, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_duplicate_rows(df, labels, frac_of_nulls=1, non_isl_mult=1, sample_frac=None):\n",
    "    \"\"\"\n",
    "    Takes a label dataframe, and duplicates certain rows until the desired class balance is obtained.\n",
    "    This function assumes a multilabel label set.\n",
    "    Arguments:\n",
    "    df: Label dataframe\n",
    "    labels: List of labels\n",
    "    frac_of_nulls: The fraction of your \"null\" data you want your labeled data to be.\n",
    "    For example, \"1\" means an equal amount of null and labeled data; 0.5 means the labeled data\n",
    "    will be half the amount of the null data, etc. Default is 1.\n",
    "    non_isl_mult: The higher this is, the larger the number of non-ISL data there will be relative\n",
    "    to the ISL data. Default is 1, which means the ratio of ISL to non-ISL rows will remain the same.\n",
    "    sample_frac: If not None, a random sample equal to sample_frac will be used.\n",
    "    For example, if sample_frac is 0.1, the total dataset will be reduced by 90%. Default None.\n",
    "    \"\"\"\n",
    "\n",
    "    yes_labels = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(labels)):\n",
    "            if df.loc[i, str(j)] == 1:\n",
    "                # Find number of rows with at least one label\n",
    "                yes_labels += 1\n",
    "                break\n",
    "\n",
    "    no_labels = len(df) - yes_labels\n",
    "\n",
    "    label_count = {}\n",
    "\n",
    "    for label in labels:\n",
    "        label_count[label] = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(labels)):\n",
    "            if df.loc[i, str(j)] == 1:\n",
    "                # Find the total number of each label\n",
    "                lbl = labels[j]\n",
    "                label_count[lbl] += 1\n",
    "\n",
    "    non_isl_count = 0\n",
    "\n",
    "    for lbl in labels:\n",
    "        if lbl != 'ISL':\n",
    "            # Find the total number of non-ISL labels\n",
    "            non_isl_count += label_count[lbl]\n",
    "\n",
    "    # We will be duplicating each non-ISL row a total of \"non_isl_tot_prod\" times.\n",
    "    non_isl_tot_prod = ((no_labels * frac_of_nulls) // non_isl_count) * non_isl_mult\n",
    "\n",
    "    # We will be duplicating each ISL row a total of \"isl_prod\" times.\n",
    "    isl_prod = (no_labels * frac_of_nulls) // label_count['ISL']\n",
    "\n",
    "    # Start by just pulling out the null labels.\n",
    "    only_nulls = df[\n",
    "        (df['0'] == 0) & (df['1'] == 0) & (df['2'] == 0) & (df['3'] == 0) & (df['4'] == 0)\n",
    "    ]\n",
    "\n",
    "    df2 = only_nulls.copy()\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        # Pull out all the rows that have a particular label\n",
    "        only_that_label = df[df[str(i)] == 1]\n",
    "\n",
    "        if labels[i] == 'ISL':\n",
    "            mult = isl_prod\n",
    "        else:\n",
    "            mult = non_isl_tot_prod\n",
    "\n",
    "        # Duplicate all the rows in the dataframe using the appropriate multiplier\n",
    "        dupes = pd.DataFrame(np.repeat(only_that_label.values, mult, axis=0), columns=df.columns)\n",
    "\n",
    "        df2 = df2.append(dupes)\n",
    "    \n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    \n",
    "    if sample_frac:\n",
    "        df2 = df2.sample(frac=sample_frac)\n",
    "        df2 = df2.reset_index(drop=True)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_duplicate_rows_multiclass(df, labels, frac_of_nulls=1, non_isl_mult=1, sample_frac=None):\n",
    "    \"\"\"\n",
    "    The same function as above, just assuming a multiclass dataset.\n",
    "    This function only works if the null class is named \"null\", all lowercase.\n",
    "    \"\"\"\n",
    "\n",
    "    label_count = {}\n",
    "\n",
    "    for label in labels:\n",
    "        label_count[label] = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(labels)):\n",
    "            if df.loc[i, str(j)] == 1:\n",
    "                lbl = labels[j]\n",
    "                label_count[lbl] += 1\n",
    "\n",
    "    non_isl_count = 0\n",
    "\n",
    "    for lbl in labels:\n",
    "        if lbl != 'ISL' and lbl != 'null':\n",
    "            non_isl_count += label_count[lbl]\n",
    "            \n",
    "    no_labels = label_count['null']\n",
    "\n",
    "    non_isl_tot_prod = ((no_labels * frac_of_nulls) // non_isl_count) * non_isl_mult\n",
    "\n",
    "    isl_prod = (no_labels * frac_of_nulls) // label_count['ISL']\n",
    "\n",
    "    null_col = str(len(labels) - 1)\n",
    "    \n",
    "    only_nulls = df[\n",
    "        (df[null_col] == 1)\n",
    "    ]\n",
    "\n",
    "    df2 = only_nulls.copy()\n",
    "\n",
    "    for i in range(len(labels) - 1):\n",
    "        only_that_label = df[df[str(i)] == 1]\n",
    "\n",
    "        if labels[i] == 'ISL':\n",
    "            mult = isl_prod\n",
    "        else:\n",
    "            mult = non_isl_tot_prod\n",
    "\n",
    "        dupes = pd.DataFrame(np.repeat(only_that_label.values, mult, axis=0), columns=df.columns)\n",
    "\n",
    "        df2 = df2.append(dupes)\n",
    "    \n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    \n",
    "    if sample_frac:\n",
    "        df2 = df2.sample(frac=sample_frac)\n",
    "        \n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration of how to use the function\n",
    "\n",
    "df = pd.read_csv('DRC_labels_multiclass_v2_train.csv')\n",
    "\n",
    "labels = ['ISL', 'SAB', 'industrial_agriculture', 'null']\n",
    "\n",
    "df2 = create_duplicate_rows_multiclass(df, labels, frac_of_nulls=1, non_isl_mult=2, sample_frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35368, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('DRC_labels_multiclass_v3_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ISL/ISL-100-100-100_1000_1100-2020-12-15-2021-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ISL/ISL-100-100-100_1000_1500-2020-12-15-2021-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ISL/ISL-100-100-100_1100_1000-2020-12-15-2021-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ISL/ISL-100-100-100_1100_1100-2020-12-15-2021-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ISL/ISL-100-100-100_1100_900-2020-12-15-2021-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  0  1                                              paths\n",
       "0           0  0  1  ISL/ISL-100-100-100_1000_1100-2020-12-15-2021-...\n",
       "1           1  0  1  ISL/ISL-100-100-100_1000_1500-2020-12-15-2021-...\n",
       "2           2  0  1  ISL/ISL-100-100-100_1100_1000-2020-12-15-2021-...\n",
       "3           3  0  1  ISL/ISL-100-100-100_1100_1100-2020-12-15-2021-...\n",
       "4           4  0  1  ISL/ISL-100-100-100_1100_900-2020-12-15-2021-0..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I needed to balance the number of SAB and null rows\n",
    "# after deciding to limit the new model to purely predicting SAB.\n",
    "\n",
    "df = pd.read_csv('DRC_labels_SAB_base_v1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', '0', '1', 'paths'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ISL/ISL-100-100-100_1000_1100-2020-12-15-2021-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ISL/ISL-100-100-100_1000_1500-2020-12-15-2021-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ISL/ISL-100-100-100_1100_1000-2020-12-15-2021-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ISL/ISL-100-100-100_1100_1100-2020-12-15-2021-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ISL/ISL-100-100-100_1100_900-2020-12-15-2021-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1                                              paths\n",
       "0  0  1  ISL/ISL-100-100-100_1000_1100-2020-12-15-2021-...\n",
       "1  0  1  ISL/ISL-100-100-100_1000_1500-2020-12-15-2021-...\n",
       "2  0  1  ISL/ISL-100-100-100_1100_1000-2020-12-15-2021-...\n",
       "3  0  1  ISL/ISL-100-100-100_1100_1100-2020-12-15-2021-...\n",
       "4  0  1  ISL/ISL-100-100-100_1100_900-2020-12-15-2021-0..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There's an extra column because I forgot to drop the index when I saved to CSV\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19819, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11891.4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating train, val, and test datasets with a 60%/20%/20% ratio.\n",
    "# First, calculate 60% and 20% of the total rows.\n",
    "19819 * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3963.8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19819 * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the dataset.\n",
    "df = df.sample(frac=1)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11892, 3)\n",
      "(3964, 3)\n",
      "(3964, 3)\n"
     ]
    }
   ],
   "source": [
    "# Divide into train, val, and test.\n",
    "df_train = df.loc[0:11891]\n",
    "df_val = df.loc[11892:11892+3963]\n",
    "df_test = df.loc[11892+3963:]\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9865\n",
       "1    2027\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I want to achieve class balance on the train dataset.\n",
    "# I don't class balance the val or test datasets because the actual data\n",
    "# we're looking to predict on won't be balanced.\n",
    "df_train['0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SAB/Shifting_cultivation-100-49-49_1600_3000-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SAB/Shifting_cultivation-100-49-49_1600_3000-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SAB/Shifting_cultivation-100-49-49_1600_3000-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SAB/Shifting_cultivation-100-81-81_5800_9800-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SAB/Shifting_cultivation-100-81-81_5800_9800-2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1                                              paths\n",
       "0  1  0  SAB/Shifting_cultivation-100-49-49_1600_3000-2...\n",
       "1  1  0  SAB/Shifting_cultivation-100-49-49_1600_3000-2...\n",
       "2  1  0  SAB/Shifting_cultivation-100-49-49_1600_3000-2...\n",
       "3  1  0  SAB/Shifting_cultivation-100-81-81_5800_9800-2...\n",
       "4  1  0  SAB/Shifting_cultivation-100-81-81_5800_9800-2..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding in three sets of duplicate SAB rows will roughly balance the dataset.\n",
    "\n",
    "only_sab = df_train[df_train['0'] == 1]\n",
    "\n",
    "dupes = pd.DataFrame(np.repeat(only_sab.values, 3, axis=0), columns=df_train.columns)\n",
    "\n",
    "dupes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6081, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6081\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes['0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17973, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.append(dupes)\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9865\n",
       "1    8108\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the dataset is roughly balanced\n",
    "\n",
    "df_train['0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>paths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>null/100_700_0.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>null/67_3500_5600.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9486</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>null/67_300_6300.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10315</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SAB/Shifting_cultivation-100-52-52_900_1400-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SAB/Shifting_cultivation-100-81-81_8200_10900-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1                                              paths\n",
       "3138   0  1                                 null/100_700_0.tif\n",
       "3232   0  1                              null/67_3500_5600.tif\n",
       "9486   0  1                               null/67_300_6300.tif\n",
       "10315  1  0  SAB/Shifting_cultivation-100-52-52_900_1400-20...\n",
       "5753   1  0  SAB/Shifting_cultivation-100-81-81_8200_10900-..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomize the train set so that all the duplicate rows aren't at the bottom.\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6611.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.reset_index(drop=True)\n",
    "\n",
    "# Now to divide into train/val/test, with a 60%/20%/20% distribution.\n",
    "df2.shape[0] * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19833.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape[0] * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19833, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_train = df2.loc[0:19832]\n",
    "df2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9984\n",
       "0    9849\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_train['0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6612, 3)\n",
      "(6611, 3)\n"
     ]
    }
   ],
   "source": [
    "df2_val = df2.loc[19833:19833+6611]\n",
    "df2_test = df2.loc[19833+6611:]\n",
    "print(df2_val.shape)\n",
    "print(df2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('DRC_labels_SAB_train_v1.csv', index=None, header=True)\n",
    "df_val.to_csv('DRC_labels_SAB_val_v1.csv', index=None, header=True)\n",
    "df_test.to_csv('DRC_labels_SAB_test_v1.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "aws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
