{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto3 import client\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'canopy-production-ml'\n",
    "\n",
    "pc_bucket = s3.Bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.Bucket(name='canopy-production-ml')\n"
     ]
    }
   ],
   "source": [
    "print(pc_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chips = []\n",
    "for obj in pc_bucket.objects.all():\n",
    "    if 'yes' in obj.key:\n",
    "        chips.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chip in chips[0:4]:\n",
    "    id = chip.key.split(\"/\")[4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_file = \"train_test_polygons.json\"\n",
    "\n",
    "with open(j_file, 'r') as j:\n",
    "    train_test = json.loads(j.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_test[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_test[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.ObjectSummary(bucket_name='canopy-production-ml', key='chips/cloudfree-merge-polygons/yes/Habitation/100/101/101_1000_3000.tif')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chips[0].key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chips/cloudfree-merge-polygons/yes/Habitation/100/101/101_1000_3000.tif'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chips[0].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'101_1000_3000.tif'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chips[0].key.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acl',\n",
       " 'Cors',\n",
       " 'Lifecycle',\n",
       " 'LifecycleConfiguration',\n",
       " 'Logging',\n",
       " 'Notification',\n",
       " 'Object',\n",
       " 'Policy',\n",
       " 'RequestPayment',\n",
       " 'Tagging',\n",
       " 'Versioning',\n",
       " 'Website',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_name',\n",
       " 'copy',\n",
       " 'create',\n",
       " 'creation_date',\n",
       " 'delete',\n",
       " 'delete_objects',\n",
       " 'download_file',\n",
       " 'download_fileobj',\n",
       " 'get_available_subresources',\n",
       " 'load',\n",
       " 'meta',\n",
       " 'multipart_uploads',\n",
       " 'name',\n",
       " 'object_versions',\n",
       " 'objects',\n",
       " 'put_object',\n",
       " 'upload_file',\n",
       " 'upload_fileobj',\n",
       " 'wait_until_exists',\n",
       " 'wait_until_not_exists']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pc_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method bucket_copy in module boto3.s3.inject:\n",
      "\n",
      "bucket_copy(CopySource, Key, ExtraArgs=None, Callback=None, SourceClient=None, Config=None) method of boto3.resources.factory.s3.Bucket instance\n",
      "    Copy an object from one S3 location to an object in this bucket.\n",
      "    \n",
      "    This is a managed transfer which will perform a multipart copy in\n",
      "    multiple threads if necessary.\n",
      "    \n",
      "    Usage::\n",
      "    \n",
      "        import boto3\n",
      "        s3 = boto3.resource('s3')\n",
      "        copy_source = {\n",
      "            'Bucket': 'mybucket',\n",
      "            'Key': 'mykey'\n",
      "        }\n",
      "        bucket = s3.Bucket('otherbucket')\n",
      "        bucket.copy(copy_source, 'otherkey')\n",
      "    \n",
      "    :type CopySource: dict\n",
      "    :param CopySource: The name of the source bucket, key name of the\n",
      "        source object, and optional version ID of the source object. The\n",
      "        dictionary format is:\n",
      "        ``{'Bucket': 'bucket', 'Key': 'key', 'VersionId': 'id'}``. Note\n",
      "        that the ``VersionId`` key is optional and may be omitted.\n",
      "    \n",
      "    :type Key: str\n",
      "    :param Key: The name of the key to copy to\n",
      "    \n",
      "    :type ExtraArgs: dict\n",
      "    :param ExtraArgs: Extra arguments that may be passed to the\n",
      "        client operation\n",
      "    \n",
      "    :type Callback: function\n",
      "    :param Callback: A method which takes a number of bytes transferred to\n",
      "        be periodically called during the copy.\n",
      "    \n",
      "    :type SourceClient: botocore or boto3 Client\n",
      "    :param SourceClient: The client to be used for operation that\n",
      "        may happen at the source object. For example, this client is\n",
      "        used for the head_object that determines the size of the copy.\n",
      "        If no client is provided, the current client is used as the client\n",
      "        for the source object.\n",
      "    \n",
      "    :type Config: boto3.s3.transfer.TransferConfig\n",
      "    :param Config: The transfer configuration to be used when performing the\n",
      "        copy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pc_bucket.copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_s3_copy(chips, j_file, bucket_name='canopy-production-ml',\n",
    "                       base_path='chips/cloudfree-merge-polygons/split/'):\n",
    "    \n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    \n",
    "    with open(j_file, 'r') as j:\n",
    "        \n",
    "        train_test_file = json.loads(j.read())\n",
    "        \n",
    "#     for split in list(train_test.keys()):\n",
    "        \n",
    "#         for polygon in train_test[split]:\n",
    "\n",
    "    length = len(chips)\n",
    "            \n",
    "    for i, chip in enumerate(chips, 1):\n",
    "        print(f'Processing chip {i} of {length}', end='\\r', flush=True)\n",
    "\n",
    "        CopySource = {\n",
    "            'Bucket': bucket_name,\n",
    "            'Key': chip.key\n",
    "        }\n",
    "\n",
    "        polygon_id = int(chip.key.split(\"/\")[5])\n",
    "\n",
    "        filename = chip.key.split('/')[-1]\n",
    "\n",
    "        if polygon_id in train_test_file[\"test\"]:\n",
    "            train_test = 'test'\n",
    "\n",
    "            #s3.Object(bucket, base_path + 'test/').copy_from(CopySource=bucket + chip.key)\n",
    "\n",
    "        else:\n",
    "            train_test = 'train_val'\n",
    "\n",
    "            #s3.Object(bucket, base_path + 'train_val/').copy_from(CopySource=bucket + chip.key)\n",
    "\n",
    "        new_key = f'{base_path}{train_test}/{polygon_id}/{filename}'\n",
    "\n",
    "        bucket.copy(CopySource, new_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chip 49133 of 49133\r"
     ]
    }
   ],
   "source": [
    "j_file = \"train_test_polygons.json\"\n",
    "train_test_s3_copy(chips, j_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://canopy-production-ml/chips/cloudfree-merge-polygons/split/\n"
     ]
    }
   ],
   "source": [
    "print('s3://canopy-production-ml/' + 'chips/cloudfree-merge-polygons/split/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "aws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
