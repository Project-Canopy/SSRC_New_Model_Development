{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32bb5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label filenames\n",
    "label_file_path_train = 'DRC_labels_SAB_train_sample.csv'\n",
    "label_file_path_val = 'DRC_labels_SAB_val_sample.csv'\n",
    "label_file_path_train_full = 'DRC_labels_SAB_train_v1.csv'\n",
    "label_file_path_val_full = 'DRC_labels_SAB_val_v1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d0c69",
   "metadata": {},
   "source": [
    "### Download training files from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a3fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bab83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = './training_chips/' # change to whichever folder you want to download the files to\n",
    "\n",
    "bucket_name = 'canopy-production-ml'\n",
    "base_key = 'chips/model2_s2cloudless/training_v2/null/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a208cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(label_file_path_train) # Change to label_file_path_train_full\n",
    "                                                  # if you want to download all training chips\n",
    "val_labels = pd.read_csv(label_file_path_val)     # Again, add _full to download all val chips\n",
    "\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_training_chip(s3, bucket_name, base_key, path, dest_dir):\n",
    "    \"\"\"\n",
    "    Downloads a training chip from s3 based on its path in the label file\n",
    "    s3: s3 client\n",
    "    bucket_name: Name of s3 bucket\n",
    "    base_key: The s3 key shared by all training chips\n",
    "    path: Path as listed in the label file\n",
    "    dest_dir: Where to download the chip to\n",
    "    \"\"\"\n",
    "    subfolder_name = path.split('/')[0]\n",
    "    subfolder_path = dest_dir + subfolder_name\n",
    "    if not os.path.exists(subfolder_path):\n",
    "        os.mkdir(subfolder_path)\n",
    "    s3_key = base_key + path\n",
    "    \n",
    "    s3.download_file(bucket_name, s3_key, subfolder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "for path in train_labels['paths']:\n",
    "    download_training_chip(s3, bucket_name, base_key, path, training_dir)\n",
    "\n",
    "for path in val_labels['paths']:\n",
    "    download_training_chip(s3, bucket_name, base_key, path, training_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b832bd",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ef8615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\test_models\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d45ab1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] # change to whichever bands you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0395d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_file_path_train: DRC_labels_SAB_train_sample.csv\n",
      "labels_file_val: DRC_labels_SAB_val_sample.csv\n",
      "No data augmentation. Please set augment to True if you want to augment training dataset\n",
      "Training on 1797 images\n",
      "Validation on 180 images \n"
     ]
    }
   ],
   "source": [
    "training_dir = 'D:/canopy_data/s2cloudless_new_model' # change to whherever you stored your training images\n",
    "\n",
    "gen = DataLoader(\n",
    "    training_dir=training_dir,\n",
    "    label_file_path_train=label_file_path_train,\n",
    "    label_file_path_val=label_file_path_val,\n",
    "    bands=bands\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c710a2bd",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1085103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da4cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic model code; feel free to modify extensively\n",
    "from sample_model import define_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b247bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 100, 100, 12)\n",
      "(None, 100, 100, 3)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "numclasses = 2\n",
    "input_shape = (100, 100, int(len(bands)))\n",
    "\n",
    "model = define_model(numclasses, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e336eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = CategoricalCrossentropy()\n",
    "\n",
    "metrics = [\n",
    "    tf.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Precision(class_id=0,name='SAB_precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.Recall(class_id=0,name='SAB_recall'),\n",
    "    F1Score(num_classes=numclasses, name=\"f1_score\")\n",
    "]\n",
    "# Can use different metrics if you want\n",
    "\n",
    "\n",
    "model.compile(loss=model_loss,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb383d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 [==============================] - 160s 3s/step - loss: 1.0854 - accuracy: 0.6683 - precision: 0.6683 - SAB_precision: 0.6614 - recall: 0.6683 - SAB_recall: 0.5207 - f1_score: 0.6537 - val_loss: 7.9738 - val_accuracy: 0.5056 - val_precision: 0.5056 - val_SAB_precision: 0.4972 - val_recall: 0.5056 - val_SAB_recall: 1.0000 - val_f1_score: 0.3637\n",
      "Epoch 2/3\n",
      "57/57 [==============================] - 141s 2s/step - loss: 0.5256 - accuracy: 0.7919 - precision: 0.7919 - SAB_precision: 0.7876 - recall: 0.7919 - SAB_recall: 0.7284 - f1_score: 0.7875 - val_loss: 7.9722 - val_accuracy: 0.5056 - val_precision: 0.5056 - val_SAB_precision: 0.4972 - val_recall: 0.5056 - val_SAB_recall: 1.0000 - val_f1_score: 0.3637\n",
      "Epoch 3/3\n",
      "57/57 [==============================] - 148s 3s/step - loss: 0.4830 - accuracy: 0.8136 - precision: 0.8136 - SAB_precision: 0.8222 - recall: 0.8136 - SAB_recall: 0.7409 - f1_score: 0.8090 - val_loss: 6.5763 - val_accuracy: 0.5556 - val_precision: 0.5556 - val_SAB_precision: 0.5244 - val_recall: 0.5556 - val_SAB_recall: 0.9773 - val_f1_score: 0.4709\n"
     ]
    }
   ],
   "source": [
    "epochs = 3 # As a starting point\n",
    "\n",
    "history = model.fit(\n",
    "    gen.training_dataset,\n",
    "    validation_data=gen.validation_dataset,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b0606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-models",
   "language": "python",
   "name": "test_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
