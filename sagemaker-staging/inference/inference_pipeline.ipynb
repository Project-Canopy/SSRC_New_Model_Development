{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local / Sagemaker Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: rasterio in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: geopandas in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: shapely in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (1.8.4)\n",
      "Requirement already satisfied: tensorflow-addons[tensorflow] in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from rasterio) (1.4.7)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from rasterio) (59.1.1)\n",
      "Requirement already satisfied: click-plugins in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.18 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from rasterio) (1.20.3)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from rasterio) (21.2.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from rasterio) (2021.10.8)\n",
      "Requirement already satisfied: cligj>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: click>=4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from rasterio) (8.0.3)\n",
      "Requirement already satisfied: affine in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from rasterio) (2.3.1)\n",
      "Requirement already satisfied: pyproj>=2.6.1.post1 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from geopandas) (3.3.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from geopandas) (21.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from geopandas) (1.3.4)\n",
      "Requirement already satisfied: fiona>=1.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from geopandas) (1.8.21)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow-addons[tensorflow]) (2.13.3)\n",
      "Requirement already satisfied: tensorflow<2.10.0,>=2.7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow-addons[tensorflow]) (2.7.1)\n",
      "Requirement already satisfied: munch in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
      "Requirement already satisfied: six>=1.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from pandas>=1.0.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from pandas>=1.0.0->geopandas) (2021.3)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from snuggs>=1.4.1->rasterio) (3.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (0.37.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (3.19.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (2.8.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (13.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (3.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (1.1.2)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (2.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (0.24.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (1.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (3.10.0.2)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (1.41.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (2.6.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (2.26.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (4.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (1.26.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.10.0,>=2.7.0->tensorflow-addons[tensorflow]) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/tensorflow2_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rasterio geopandas shapely tensorflow-addons[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from rasterio.windows import Window\n",
    "from glob import glob\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "from rasterio.windows import get_data_window\n",
    "import rasterio as rio\n",
    "from inference_predict import *\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "# import gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windowing\n",
    "\n",
    "Define windows code to run inference on 1km x 1km areas (or however big the chips you trained on were) without having to actually chip out the rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(img_dim, patch_size=(240, 240), stride=(240, 240)):\n",
    "    patch_size = np.array(patch_size)\n",
    "    stride = np.array(stride)\n",
    "    img_dim = np.array(img_dim)\n",
    "    # to take into account edges, add additional blocks around right side edge and bottom edge of raster\n",
    "    new_img_dim = [img_dim[0] + stride[0],img_dim[1] + stride[0]]\n",
    "    \n",
    "    max_dim = (new_img_dim//patch_size)*patch_size - patch_size\n",
    "\n",
    "    ys = np.arange(0, img_dim[0], stride[0])\n",
    "    xs = np.arange(0, img_dim[1], stride[1])\n",
    "\n",
    "    tlc = np.array(np.meshgrid(ys, xs)).T.reshape(-1, 2)\n",
    "    tlc = tlc[tlc[:, 0] <= max_dim[0]]\n",
    "    tlc = tlc[tlc[:, 1] <= max_dim[1]]\n",
    "    \n",
    "    windows = []\n",
    "    for y,x in tlc.astype(int):\n",
    "        windows.append(Window(x, y, patch_size[1], patch_size[0]))\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ndvi(data, dtype_1=rio.float32):\n",
    "    \n",
    "    nir = data[3].astype(dtype_1)\n",
    "    red = data[2].astype(dtype_1)\n",
    "\n",
    "    # Allow division by zero\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi = ((nir - red) / (nir + red)).astype(dtype_1)\n",
    "\n",
    "    # Rescaling for use in 16bit output\n",
    "\n",
    "    ndvi = (ndvi + 1) * (2**15 - 1)\n",
    "\n",
    "    # Add NDVI band to end of array    \n",
    "    rast = np.concatenate((data,[ndvi]),axis=0)\n",
    "    \n",
    "    rast = rast.astype(rio.uint16)\n",
    "    \n",
    "    return rast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change URLs to download different models\n",
    "model_url = \"s3://canopy-production-ml/inference/model_files/model-best.h5\"\n",
    "weights_url = \"s3://canopy-production-ml/inference/model_files/model_weights_best.h5\"\n",
    "\n",
    "download_model(model_url,weights_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-03 03:16:28.681102: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-09-03 03:16:28.681181: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-16-23-61.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-09-03 03:16:28.681974: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model.h5\",\"model_weights.h5\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label_list if you have different labels\n",
    "label_list = [\"Industrial_agriculture\",\"ISL\",\"Mining\",\"Roads\",\"Shifting_cultivation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3033"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# create list of rasters to run inference on\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket_name = 'canopy-production-ml'\n",
    "\n",
    "pc_bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "prefix = 'full_drc/2019/' # change to whichever directory your rasters are in\n",
    "\n",
    "rasters_list_2019 = []\n",
    "\n",
    "for obj in pc_bucket.objects.all():\n",
    "    #if train_uri in obj.key:\n",
    "    #    train_chips.append(obj.key)\n",
    "    if prefix in obj.key:\n",
    "        rasters_list_2019.append(obj.key)\n",
    "    \n",
    "len(rasters_list_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_windows(granule_dir,patch_size=100,\n",
    "                   stride=100,SAVE=False,\n",
    "                   bands=[1, 2, 3, 4, 5, 6], \n",
    "                  model=model,\n",
    "                   predict_thresh=.5,\n",
    "                  label_list=label_list, \n",
    "                    current_output={}):\n",
    "    \n",
    "    \"\"\"\n",
    "    Runs the model on the rasters in granule_dir and outputs dictionary containing predictions\n",
    "    Arguments:\n",
    "    granule_dir: Directory containing granules you want to run inference on\n",
    "    patch_size: Size of the window you want to run the model on\n",
    "    stride: After running inference on one window, how far to move before defining the next window.\n",
    "    Should be same as \"patch-size\" unless you have a very good reasn for it not to be.\n",
    "    bands: Which bands to use for the inference\n",
    "    model: tensorflow model to use\n",
    "    predict_thresh: Probability threshold to assign a label\n",
    "    label_list: List of labels\n",
    "    current_output: if this function is being run concurrently, put your most recent\n",
    "    output_dict into this argument.\n",
    "    \"\"\"\n",
    "    \n",
    "    granule_list = glob(f'{granule_dir}/*.tif')\n",
    "    \n",
    "    output_dict = current_output.copy()\n",
    "    \n",
    "    granule_id_list = []\n",
    "    \n",
    "    window_id_list = []\n",
    "    \n",
    "    window_geom_list = []\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    label_master_list = []\n",
    "    \n",
    "    gdf_list = []\n",
    "    \n",
    "    timestamp = gen_timestamp()\n",
    "    \n",
    "    for j,granule_path in enumerate(granule_list):\n",
    "        \n",
    "        granule_id = granule_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "        with rio.open(granule_path) as src:\n",
    "\n",
    "            windows = get_windows(src.shape, (patch_size, patch_size), (stride, stride))\n",
    "\n",
    "            for i, window in enumerate(windows):\n",
    "                \n",
    "                #print(f\"predicting window {i + 1} of {len(windows)} of granulate {j + 1} of {len(granule_list)}\",end='\\r', flush=True)\n",
    "                \n",
    "                label_name_list = []\n",
    "                \n",
    "                window_id = i+1\n",
    "\n",
    "                data = src.read(bands,window=window, masked=True)\n",
    "\n",
    "                data = add_ndvi(data)\n",
    "        \n",
    "                shape = data.shape\n",
    "            \n",
    "                new_shape = (data.shape[0],patch_size,patch_size)\n",
    "            \n",
    "                if shape != new_shape:\n",
    "\n",
    "                    filled_array = np.full(new_shape, 0)\n",
    "                    filled_array[:shape[0],:shape[1],:shape[2]] = data\n",
    "                    data = filled_array\n",
    "                    window = Window(window.col_off,window.row_off,shape[2],shape[1])\n",
    "                    \n",
    "                    \n",
    "                #image pre-processing / inference\n",
    "                prediction = model.predict(read_image_tf_out(data))\n",
    "                prediction = np.where(prediction > predict_thresh, 1, 0)\n",
    "                prediction_i = np.where(prediction == 1)[1]\n",
    "                for i in prediction_i:\n",
    "                    label_name_list.append(label_list[i])\n",
    "                \n",
    "                label_master_list.append(label_name_list)\n",
    "                \n",
    "                #vectorizing raster bounds for visualization \n",
    "                window_bounds = rio.windows.bounds(window, src.transform, height=patch_size, width=patch_size)\n",
    "                geom = box(*window_bounds)\n",
    "                geom_coords = list(geom.exterior.coords)\n",
    "#                 window_geom_list.append(geom)\n",
    "                \n",
    "                #create or append to dict....\n",
    "                \n",
    "                if granule_id in output_dict:\n",
    "\n",
    "                    output_dict[granule_id].append({\"window_id\":window_id,\"polygon_coords\":geom_coords,\"labels\":label_name_list})\n",
    "\n",
    "                else:\n",
    "\n",
    "                    output_dict[granule_id] = [{\"window_id\":window_id,\"polygon_coords\":geom_coords,\"labels\":label_name_list}]\n",
    "        \n",
    "        #save_to_s3(output_dict,output_filename,job_name,timestamp)\n",
    "        \n",
    "\n",
    "\n",
    "#             gdf = gpd.GeoDataFrame({\"granule_id\":granule_id_list,\"window_id\":window_id_list,\"geometry\":window_geom_list,\"labels\":label_master_list})\n",
    "#             gdf[\"labels\"] = gdf[\"labels\"].astype(str)\n",
    "\n",
    "#             gdf_list.append(gdf)\n",
    "            \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I download rasters from S3 one at a time, run inference on it, save the results in a json file, then delete the raster. This is to ensure only one raster file is in storage at any given time.\n",
    "\n",
    "Note the distinction between \"old_json_name\" and \"new_json_name.\" Each time I run inference on a new raster, I save the results in a *new* json file, and only after that's done do I delete the old json file. This is to ensure that most data is not lost if the notebook is interrupted while writing the new json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster 3032 of 3032\r"
     ]
    }
   ],
   "source": [
    "granule_dir = './rasters_isl_2019/' # directory to store downloaded rasters in\n",
    "json_filename_base = \"ISL_2019_results_fixed\" # name for the json file used to log results\n",
    "new_json_name = json_filename_base + '_2019_549.json' # most recent json filename\n",
    "with open(new_json_name, 'r') as openfile:\n",
    "    od = json.load(openfile)\n",
    "length = len(rasters_list_2019) - 1\n",
    "\n",
    "for i, s3_path in enumerate(rasters_list_2019[1:]):\n",
    "    \n",
    "    name = s3_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    if name not in od.keys(): # only run inference if the raster isn't in the json file\n",
    "    \n",
    "        print(f'Raster {i+1} of {length}', end='\\r', flush=True)\n",
    "\n",
    "        filename = s3_path.split('/')[-1]\n",
    "\n",
    "        filepath = granule_dir + filename\n",
    "\n",
    "        s3.download_file(bucket_name, s3_path, filepath) # download raster from S3\n",
    "    \n",
    "        output_dict = output_windows_2(granule_dir, current_output=od) # run inference\n",
    "        \n",
    "        old_json_name = new_json_name\n",
    "        \n",
    "        new_json_name = json_filename_base + '_' + name + '.json' # create new json filename\n",
    "    \n",
    "        with open(new_json_name, \"w\") as outfile:\n",
    "            json.dump(output_dict, outfile) # dump inference results into new json file\n",
    "    \n",
    "        with open(new_json_name, 'r') as openfile:\n",
    "            od = json.load(openfile) # load those results into \"od\" variable\n",
    "        \n",
    "        os.remove(filepath) # delete raster file\n",
    "        \n",
    "        os.remove(old_json_name) # delete old json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of each label\n",
    "data = output_dict\n",
    "\n",
    "count = {}\n",
    "label_match_results = []\n",
    "granule_count = len(data.keys())\n",
    "granule_list = data.keys()\n",
    "count[\"granule_count\"] = granule_count\n",
    "for k1 in list(data.keys()):\n",
    "    for i in range(len(data[k1])):\n",
    "        if len(data[k1][i]['labels']) == 0:\n",
    "            if \"null_chips\" not in count.keys():\n",
    "                count[\"null_chips\"] = 1\n",
    "            else:\n",
    "                count[\"null_chips\"] += 1 \n",
    "        for label in data[k1][i]['labels']:\n",
    "            if label not in count.keys():\n",
    "                count[label] = 1 \n",
    "            else:\n",
    "                    count[label] += 1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'granule_count': 1,\n",
       " 'null_chips': 1512,\n",
       " 'Shifting_cultivation': 336,\n",
       " 'ISL': 82,\n",
       " 'Roads': 5,\n",
       " 'Industrial_agriculture': 1}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
